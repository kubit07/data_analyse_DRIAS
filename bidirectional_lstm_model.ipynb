{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e7b0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dvesa\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns \n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Température - Tour Sud - 2ème Étage\n",
    "tour_sud_2_temp = ['S2STemp', 'S2OTemp', 'S2ETemp', 'S2NTemp']\n",
    "\n",
    "# Désignation: Tour-Etage-Orientation-Temp/HR (S1NTemp: Tour Sud- 1er Etage- Orientation Nord- Température)\n",
    "designations = {\n",
    "    'N1NTemp': 'Tour Nord - 1er Étage - Orientation Nord - Température',\n",
    "    'N1ETemp': 'Tour Nord - 1er Étage - Orientation Est - Température',\n",
    "    'N1STemp': 'Tour Nord - 1er Étage - Orientation Sud - Température',\n",
    "    'N1OTemp': 'Tour Nord - 1er Étage - Orientation Ouest - Température',\n",
    "    'S1NTemp': 'Tour Sud - 1er Étage - Orientation Nord - Température',\n",
    "    'S1OTemp': 'Tour Sud - 1er Étage - Orientation Ouest - Température',\n",
    "    'N2STemp': 'Tour Nord - 2ème Étage - Orientation Sud - Température',\n",
    "    'N2OTemp': 'Tour Nord - 2ème Étage - Orientation Ouest - Température',\n",
    "    'N2ETemp': 'Tour Nord - 2ème Étage - Orientation Est - Température',\n",
    "    'N2NTemp': 'Tour Nord - 2ème Étage - Orientation Nord - Température',\n",
    "    'S2STemp': 'Tour Sud - 2ème Étage - Orientation Sud - Température',\n",
    "    'S2OTemp': 'Tour Sud - 2ème Étage - Orientation Ouest - Température',\n",
    "    'S2ETemp': 'Tour Sud - 2ème Étage - Orientation Est - Température',\n",
    "    'S2NTemp': 'Tour Sud - 2ème Étage - Orientation Nord - Température',\n",
    "    'S2OHR': 'Tour Sud - 2ème Étage - Orientation Ouest - Humidité Relative',\n",
    "    'S2SHR': 'Tour Sud - 2ème Étage - Orientation Sud - Humidité Relative',\n",
    "    'S2EHR': 'Tour Sud - 2ème Étage - Orientation Est - Humidité Relative',\n",
    "    'S2NHR': 'Tour Sud - 2ème Étage - Orientation Nord - Humidité Relative',\n",
    "    'N2SHR': 'Tour Nord - 2ème Étage - Orientation Sud - Humidité Relative',\n",
    "    'N2OHR': 'Tour Nord - 2ème Étage - Orientation Ouest - Humidité Relative',\n",
    "    'N2EHR': 'Tour Nord - 2ème Étage - Orientation Est - Humidité Relative',\n",
    "    'N2NHR': 'Tour Nord - 2ème Étage - Orientation Nord - Humidité Relative',\n",
    "    'tour_nord_1_temp': 'Température - Tour Nord - 1er Étage',\n",
    "    'tour_sud_1_temp': 'Température - Tour Sud - 1er Étage',\n",
    "    'tour_sud_2_temp': 'Température - Tour Sud - 2ème Étage',\n",
    "    'tour_nord_2_temp': 'Température - Tour Nord - 2ème Étage'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Températures, Humidité\n",
    "Temp_HR = ['N1NTemp', 'N1ETemp', 'N1STemp', 'N1OTemp', 'S1NTemp', 'S1OTemp', 'N2STemp', 'N2OTemp', 'N2ETemp', 'N2NTemp', 'S2STemp', 'S2OTemp', 'S2ETemp', 'S2NTemp', 'N2SHR', 'N2OHR', 'N2EHR', 'N2NHR', 'S2SHR', 'S2OHR', 'S2EHR', 'S2NHR']\n",
    "\n",
    "# Humidité, Températures (Tour Nord 2 Etages)\n",
    "tour_nord_2_temp_HR = [(\"N2STemp\", \"N2SHR\"), (\"N2OTemp\", \"N2OHR\"), (\"N2ETemp\", \"N2EHR\"), (\"N2NTemp\", \"N2NHR\")]\n",
    "tour_sud_2_temp_HR = [(\"S2STemp\", \"S2SHR\"), (\"S2OTemp\", \"S2OHR\"), (\"S2ETemp\", \"S2EHR\"), (\"S2NTemp\", \"S2NHR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, train_size=0.7, val_size=0.2):\n",
    "    \"\"\"\n",
    "    Découpe un DataFrame temporel en trois parties : train, val, test,\n",
    "    en respectant l'ordre chronologique.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Données à découper (indexé ou non par le temps)\n",
    "        train_size (float): Proportion pour l'ensemble d'entraînement\n",
    "        val_size (float): Proportion pour la validation\n",
    "\n",
    "    Returns:\n",
    "        df_train, df_val, df_test (DataFrames)\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    train_end = int(n * train_size)\n",
    "    val_end = int(n * (train_size + val_size))\n",
    "\n",
    "    df_train = df.iloc[:train_end]\n",
    "    df_val = df.iloc[train_end:val_end]\n",
    "    df_test = df.iloc[val_end:]\n",
    "\n",
    "    print(f\"Train size : {len(df_train)}\")\n",
    "    print(f\"Val size : {len(df_val)}\")\n",
    "    print(f\"Test size : {len(df_test)}\")\n",
    "\n",
    "    return df_train.copy(), df_val.copy(), df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea12f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcule et affiche les métriques MAE, RMSE et R² entre les vraies valeurs et les prédictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): Valeurs réelles.\n",
    "        y_pred (array-like): Valeurs prédites.\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f'MAE: {mae:.4f}')\n",
    "    print(f'RMSE: {rmse:.4f}')\n",
    "    print(f'R2 Score: {r2:.4f}')\n",
    "    \n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea295d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):  \n",
    "    Xs, ys = [], []   \n",
    "    for i in range(len(X) - time_steps):   \n",
    "        v = X.iloc[i:(i + time_steps)].values \n",
    "        Xs.append(v)      \n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "    \"\"\"\n",
    "This function prepares the input features and target values in the format required for training a recurrent neural network (RNN) or LSTM model for sequential prediction tasks. It creates sequences of input features and their corresponding target values, which can be fed into the model during training.\n",
    "\n",
    "    - X: This parameter represents the input features, typically a pandas DataFrame containing multiple time-series variables such as temperature, humidity, etc.\n",
    "    - y: This parameter represents the target values, which are typically the values we want to predict based on the input features.\n",
    "    - time_steps: This parameter defines the length of each sequence. It determines how many data points from the past will be used to predict the next data point. For example, if time_steps is set to 3, the function will create sequences of three consecutive data points as input features and the next data point as the target value.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a088ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_bilstm(X_train, y_train, X_val, y_val, sequence_length, units=100, \n",
    "                           activation='tanh', epochs=30, batch_size=32, patience=10):\n",
    "    \"\"\"\n",
    "    Construit, entraîne et évalue un modèle BiLSTM avec early stopping.\n",
    "\n",
    "    Args:\n",
    "        X_train (ndarray): Données d'entraînement (3D).\n",
    "        y_train (ndarray): Cibles d'entraînement.\n",
    "        X_val (ndarray): Données de validation (3D).\n",
    "        y_val (ndarray): Cibles de validation.\n",
    "        sequence_length (int): Longueur des séquences en entrée.\n",
    "        units (int): Nombre de neurones dans la couche LSTM.\n",
    "        activation (str): Fonction d'activation de la couche LSTM.\n",
    "        epochs (int): Nombre d’époques d’entraînement.\n",
    "        batch_size (int): Taille de lot pour l’entraînement.\n",
    "        patience (int): Patience pour l’early stopping.\n",
    "\n",
    "    Returns:\n",
    "        model: Le modèle entraîné.\n",
    "        history: L'historique d'entraînement.\n",
    "        val_loss: La perte de validation finale.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units, activation=activation, input_shape=(sequence_length, X_train.shape[2]))))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_loss = model.evaluate(X_val, y_val, verbose=0)\n",
    "    display(f'Validation Loss: {val_loss}')\n",
    "\n",
    "    return model, history, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa105ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_drias(path_fichier_excel):\n",
    "    \"\"\"\n",
    "    Charge un fichier Excel DRIAS avec une colonne 'Date' au format '%d/%m/%Y',\n",
    "    et retourne un DataFrame avec la date en index.\n",
    "\n",
    "    Args:\n",
    "        path_fichier_excel (str): Chemin vers le fichier Excel.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Données DRIAS avec l'index daté.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(path_fichier_excel)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "    df.set_index('Date', inplace=True)\n",
    "    display(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_inverse_transform(model, X, y, target_transformer):\n",
    "    \"\"\"\n",
    "    Effectue la prédiction avec le modèle donné et applique l'inverse de la transformation \n",
    "    sur les prédictions et les vraies valeurs cibles.\n",
    "\n",
    "    Args:\n",
    "        model: Modèle entraîné (ex. BiLSTM).\n",
    "        X_val: Données d'entrée de validation.\n",
    "        y_val: Vraies valeurs cibles de validation.\n",
    "        target_transformer: Transformateur utilisé pour normaliser les cibles (ex. MinMaxScaler).\n",
    "\n",
    "    Returns:\n",
    "        Tuple (y_pred_original_scale, y_true_original_scale)\n",
    "    \"\"\"\n",
    "    # Prédiction\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Inversion de la transformation des prédictions\n",
    "    y_pred_inv = target_transformer.inverse_transform(y_pred)\n",
    "\n",
    "    # Reshape puis inversion de la transformation des vraies valeurs\n",
    "    y = y.reshape(-1, 1)\n",
    "    y_val_inv = target_transformer.inverse_transform(y)\n",
    "\n",
    "    return y_pred_inv, y_val_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c527d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_mean_max_min(data1, data2, label1, label2, start_year=2006, end_year=2025, plot_min_max=False):\n",
    "    \"\"\"\n",
    "    Compare les températures (moyenne, min, max) de deux ensembles de données \n",
    "    sur une série d'années données en superposant les courbes de chaque année\n",
    "    sur un axe temporel standardisé (année 2000).\n",
    "\n",
    "    Paramètres :\n",
    "        data1, data2 : DataFrames pandas avec un index datetime.\n",
    "        label1, label2 : noms à afficher pour identifier les deux jeux de données.\n",
    "        start_year, end_year : année de début et de fin (incluses).\n",
    "        plot_min_max : booléen pour activer/désactiver les courbes min et max.\n",
    "    \"\"\"\n",
    "    annees = range(start_year, end_year + 1)\n",
    "    n_subplots = len(annees)\n",
    "    n_cols = 2\n",
    "    n_rows = n_subplots\n",
    "\n",
    "    plt.figure(figsize=(n_cols * 14, n_rows * 5))\n",
    "    \n",
    "    for i, annee in enumerate(annees, start=1):\n",
    "        # ----- Sous-graphique 1 : data1 -----\n",
    "        plt.subplot(n_rows, n_cols, 2 * (i - 1) + 1)\n",
    "        df1 = data1[data1.index.year == annee].copy()\n",
    "        df1.index = df1.index.map(lambda d: d.replace(year=2000))\n",
    "\n",
    "        df1[\"tasAdjust\"].plot(label=f\"Temp Moyenne {annee}\", color=\"blue\", lw=2)\n",
    "        if plot_min_max:\n",
    "            df1.get(\"tasmaxAdjust\", pd.Series(index=df1.index)).plot(label=\"Max\", color=\"red\", lw=1)\n",
    "            df1.get(\"tasminAdjust\", pd.Series(index=df1.index)).plot(label=\"Min\", color=\"green\", lw=1)\n",
    "\n",
    "        _format_axes(title=f\"{label1} : {annee}\")\n",
    "\n",
    "        # ----- Sous-graphique 2 : data2 -----\n",
    "        plt.subplot(n_rows, n_cols, 2 * (i - 1) + 2)\n",
    "        df2 = data2[data2.index.year == annee].copy()\n",
    "        df2.index = df2.index.map(lambda d: d.replace(year=2000))\n",
    "\n",
    "        df2[\"2m_Temperature_C\"].plot(label=f\"Temp Moyenne {annee}\", color=\"blue\", lw=2)\n",
    "        if plot_min_max:\n",
    "            df2.get(\"MAX_TEMPERATURE_C\", pd.Series(index=df2.index)).plot(label=\"Max\", color=\"red\", lw=1)\n",
    "            df2.get(\"MIN_TEMPERATURE_C\", pd.Series(index=df2.index)).plot(label=\"Min\", color=\"green\", lw=1)\n",
    "\n",
    "        _format_axes(title=f\"{label2} : {annee}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _format_axes(title):\n",
    "    \"\"\"Formate les axes d'une sous-figure avec date sur l'axe X\"\"\"\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "    plt.xlabel(\"Mois\")\n",
    "    plt.ylabel(\"Température (°C)\")\n",
    "    plt.title(title)\n",
    "    plt.ylim(-10, 40)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2be44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_mapping_correction(obs_series, mod_series, n_quantiles=100):\n",
    "    \"\"\"\n",
    "    Correction de biais par méthode Quantile Mapping entre séries d'observations et de modèles\n",
    "\n",
    "    Paramètres :\n",
    "        obs_series : pd.Series (Données observées, index temporel)\n",
    "        mod_series : pd.Series (Données du modèle à corriger, index temporel)\n",
    "        n_quantiles : int (Nombre de quantiles pour la correction)\n",
    "\n",
    "    Retour :\n",
    "        pd.Series (Série corrigée du modèle)\n",
    "    \"\"\"\n",
    "    # Vérification des entrées\n",
    "    if not isinstance(obs_series, pd.Series) or not isinstance(mod_series, pd.Series):\n",
    "        raise TypeError(\"Les entrées doivent être des pandas Series\")\n",
    "    \n",
    "    # Trouver l'intersection temporelle\n",
    "    common_index = obs_series.index.intersection(mod_series.index)\n",
    "    \n",
    "    if len(common_index) == 0:\n",
    "        raise ValueError(\"Aucune période d'intersection entre les séries\")\n",
    "    \n",
    "    # Échantillonnage des données communes\n",
    "    obs_common = obs_series.loc[common_index].dropna()\n",
    "    mod_common = mod_series.loc[common_index].dropna()\n",
    "    \n",
    "    # Vérification des points de données\n",
    "    n_points = min(len(obs_common), len(mod_common))\n",
    "    if n_points < 2:\n",
    "        raise ValueError(\"Pas assez de données communes pour la correction\")\n",
    "    \n",
    "    # Calcul des quantiles (avec protection contre le surapprentissage)\n",
    "    n_quantiles = min(n_quantiles, max(n_points // 10, 2))\n",
    "    quantiles = np.linspace(0, 1, n_quantiles)\n",
    "    \n",
    "    # Calcul des valeurs de quantiles\n",
    "    obs_quantiles = np.nanquantile(obs_common, quantiles)\n",
    "    mod_quantiles = np.nanquantile(mod_common, quantiles)\n",
    "    \n",
    "    # Création des fonctions d'interpolation\n",
    "    # CDF du modèle\n",
    "    cdf_model = interp1d(\n",
    "        mod_quantiles, \n",
    "        quantiles, \n",
    "        kind='linear',\n",
    "        bounds_error=False, \n",
    "        fill_value=(0, 1)\n",
    "    )  # Parenthèse fermante ajoutée ici\n",
    "    \n",
    "    # Inverse de la CDF des observations\n",
    "    inv_cdf_obs = interp1d(\n",
    "        quantiles, \n",
    "        obs_quantiles, \n",
    "        kind='linear',\n",
    "        bounds_error=False,\n",
    "        fill_value=(obs_quantiles[0], obs_quantiles[-1])\n",
    "    )  # Parenthèse fermante ajoutée ici\n",
    "    \n",
    "    # Application de la correction à toute la série\n",
    "    mod_quantiles = cdf_model(mod_series.values)\n",
    "    corrected_values = inv_cdf_obs(mod_quantiles)\n",
    "    \n",
    "    # Création de la série de sortie\n",
    "    return pd.Series(\n",
    "        corrected_values, \n",
    "        index=mod_series.index, \n",
    "        name=f\"{mod_series.name}_corrected\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04306a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_q_en_rh(q_kgkg, temperature_C, pression_hPa=1013.25):\n",
    "    \"\"\"\n",
    "    Convertit une série d'humidité spécifique (kg/kg) et de température (°C)\n",
    "    en humidité relative (%) en supposant une pression constante.\n",
    "\n",
    "    Paramètres :\n",
    "        q_kgkg : pd.Series ou np.array d'humidité spécifique (kg/kg)\n",
    "        temperature_C : pd.Series ou np.array de température (°C)\n",
    "        pression_hPa : pression atmosphérique en hPa (par défaut = 1013.25)\n",
    "\n",
    "    Retour :\n",
    "        pd.Series ou np.array d'humidité relative (%) — même type que l'entrée\n",
    "    \"\"\"\n",
    "    q = np.asarray(q_kgkg)\n",
    "    T = np.asarray(temperature_C)\n",
    "\n",
    "    # Pression partielle de vapeur d'eau (e) [hPa]\n",
    "    e = (q * pression_hPa) / (0.622 + 0.378 * q)\n",
    "\n",
    "    # Pression de vapeur saturante (e_s) [hPa] — formule de Tetens\n",
    "    e_s = 6.112 * np.exp((17.67 * T) / (T + 243.5))\n",
    "\n",
    "    # Humidité relative RH [%]\n",
    "    RH = 100 * e / e_s\n",
    "    RH = np.clip(RH, 0, 100)\n",
    "\n",
    "    # Renvoyer dans le même format que l'entrée\n",
    "    if isinstance(q_kgkg, pd.Series):\n",
    "        return pd.Series(RH, index=q_kgkg.index, name='RH_%')\n",
    "    else:\n",
    "        return RH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_linear(\n",
    "    X,\n",
    "    y,\n",
    "    années_entrainement=('2018', '2019'),\n",
    "    epochs=100,\n",
    "    batch_size=8\n",
    "):\n",
    "    \"\"\"\n",
    "    Entraîne un réseau de neurones pour prédire une variable (ex. température)\n",
    "    à partir d'une série temporelle d'entrée, toutes deux au format Series.\n",
    "\n",
    "    Paramètres :\n",
    "    -----------\n",
    "    X : pd.Series\n",
    "        Série d'entrée (ex : température issue de DRIAS corrigé).\n",
    "    y : pd.Series\n",
    "        Série cible à prédire (ex : température mesurée à la basilique).\n",
    "    années_entrainement : tuple(str, str)\n",
    "        Période d'entraînement (ex. ('2018', '2019')).\n",
    "    epochs : int\n",
    "        Nombre d’époques d'entraînement.\n",
    "    batch_size : int\n",
    "        Taille des batchs.\n",
    "\n",
    "    Retourne :\n",
    "    ----------\n",
    "    model : modèle Keras entraîné\n",
    "    df_prédictions : pd.Series des prédictions pour toutes les dates de X\n",
    "    history : historique d'entraînement du modèle\n",
    "    \"\"\"\n",
    "\n",
    "    # Vérification des types\n",
    "    if not isinstance(X, pd.Series) or not isinstance(y, pd.Series):\n",
    "        raise ValueError(\"X et y doivent être des pd.Series.\")\n",
    "\n",
    "    # 1. Restriction aux années d'entraînement\n",
    "    X_train = X.loc[années_entrainement[0]:années_entrainement[1]]\n",
    "    y_train = y.loc[années_entrainement[0]:années_entrainement[1]]\n",
    "\n",
    "    # 2. Aligner les index\n",
    "    X_train, y_train = X_train.align(y_train, join='inner')\n",
    "\n",
    "    # 3. Mise en forme pour Keras\n",
    "    X_train_vals = X_train.values.reshape(-1, 1)\n",
    "    y_train_vals = y_train.values.reshape(-1, 1)\n",
    "\n",
    "    # 4. Définition du modèle\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(1,)),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 5. Entraînement\n",
    "    history = model.fit(\n",
    "        X_train_vals, y_train_vals,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 6. Prédictions sur toutes les dates de X\n",
    "    X_all_vals = X.values.reshape(-1, 1)\n",
    "    y_pred = model.predict(X_all_vals).flatten()\n",
    "    df_prédictions = pd.Series(y_pred, index=X.index)\n",
    "\n",
    "    return model, df_prédictions, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_each_year_separately(serie1, serie2, label1='Série 1', label2='Série 2'):\n",
    "    \"\"\"\n",
    "    Affiche une figure distincte pour chaque année, en comparant deux séries de température \n",
    "    sur les dates communes.\n",
    "\n",
    "    Paramètres :\n",
    "    -----------\n",
    "    serie1, serie2 : pd.Series\n",
    "        Séries temporelles avec un index datetime.\n",
    "    label1, label2 : str\n",
    "        Noms à afficher dans les légendes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Aligner sur les dates communes\n",
    "    serie1, serie2 = serie1.align(serie2, join='inner')\n",
    "\n",
    "    # Extraire les années communes\n",
    "    années = sorted(set(serie1.index.year))\n",
    "\n",
    "    for annee in années:\n",
    "        s1 = serie1[serie1.index.year == annee].copy()\n",
    "        s2 = serie2[serie2.index.year == annee].copy()\n",
    "\n",
    "        if s1.empty or s2.empty:\n",
    "            continue\n",
    "\n",
    "        # Créer une figure par année\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(s1.index, s1.values, label=label1, color='blue')\n",
    "        plt.plot(s2.index, s2.values, label=label2, color='orange')\n",
    "        plt.title(f\"Évolution de la température – {annee}\")\n",
    "        plt.xlabel({annee})\n",
    "        plt.ylabel(\"Température (°C)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a186970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def train_temperature_model(X, y, epochs=100, batch_size=32, validation_split=0.2):\n",
    "    \"\"\"\n",
    "    Construit, compile et entraîne un modèle Keras pour prédire 24 températures horaires.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : ndarray shape (n_samples, n_features)\n",
    "        Tableau des caractéristiques d’entrée (ex. Tmin, Tmoy, Tmax, jour_annee, mois).\n",
    "    y : ndarray shape (n_samples, n_outputs)\n",
    "        Tableau des cibles (24 températures horaires).\n",
    "    epochs : int, optional (default=100)\n",
    "        Nombre d’époques d’entraînement.\n",
    "    batch_size : int, optional (default=32)\n",
    "        Taille du batch.\n",
    "    validation_split : float, optional (default=0.2)\n",
    "        Fraction des données réservée à la validation.\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    model : keras.Model\n",
    "        Le modèle entraîné.\n",
    "    history : keras.callbacks.History\n",
    "        L’historique d’entraînement (pertes et métriques).\n",
    "    \"\"\"\n",
    "    input_dim  = X.shape[1]\n",
    "    output_dim = y.shape[1]\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(output_dim)                         # régression, donc pas d’activation finale\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    history = model.fit(X, y,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=validation_split,\n",
    "                        verbose=1)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e8e6f1",
   "metadata": {},
   "source": [
    "#### **Dataset DRIAS RCP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6 = load_data_drias('Drias/CNRM-CERFACS-CNRM-CM5_CNRM-ALADIN63_rcp2.6_METEO-FRANCE_ADAMONT-France_SAFRAN_day_2006_2100.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2114086",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_4_5 = load_data_drias('Drias/CNRM-CERFACS-CNRM-CM5_CNRM-ALADIN63_rcp4.5_METEO-FRANCE_ADAMONT-France_SAFRAN_day_2006_2100.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ae886",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_8_5 = load_data_drias('Drias/CNRM-CERFACS-CNRM-CM5_CNRM-ALADIN63_rcp8.5_METEO-FRANCE_ADAMONT-France_SAFRAN_day_2006_2100.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df571d04",
   "metadata": {},
   "source": [
    "#### **Dataset Historique-Météo** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des années à importer\n",
    "annees = range(2009, 2026)\n",
    "\n",
    "# Liste pour stocker les DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Boucle sur les années\n",
    "for annee in annees:\n",
    "    nom_fichier = f\"Historique-Météo/export-reims{annee}.csv\"\n",
    "    df = pd.read_csv(nom_fichier, skiprows=3)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatène tous les DataFrames en un seul\n",
    "data_climate_reims_2009_2025 = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eea625",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_climate_reims_2009_2025['DATE'] = pd.to_datetime(data_climate_reims_2009_2025['DATE'], format='%Y-%m-%d')\n",
    "data_climate_reims_2009_2025.set_index('DATE', inplace=True)\n",
    "data_climate_reims_2009_2025.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN_TEMPERATURE_C\n",
    "colonnes_temp_horaires = [\n",
    "    'TEMPERATURE_MORNING_C_6H',\n",
    "    'TEMPERATURE_NOON_C_12H',\n",
    "    'TEMPERATURE_EVENING_C_18H',\n",
    "    'TEMPERATURE_NIGHT_C_3H',\n",
    "    'TEMPERATURE_9H',\n",
    "    'TEMPERATURE_15H',\n",
    "    'TEMPERATURE_21H',\n",
    "    'TEMPERATURE_MIDNIGHT_0H'\n",
    "]\n",
    "\n",
    "# Calcul de la moyenne journalière basée uniquement sur les températures horaires\n",
    "data_climate_reims_2009_2025['MEAN_TEMPERATURE_C'] = data_climate_reims_2009_2025[colonnes_temp_horaires].mean(axis=1)\n",
    "data_climate_reims_2009_2025['MEAN_TEMPERATURE_C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ced9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp2.6\n",
    "common_index_data_rcp_2_6 = data_rcp_2_6.index.intersection(data_climate_reims_2009_2025.index)\n",
    "data_rcp_2_6_2009_2025 = data_rcp_2_6.loc[common_index_data_rcp_2_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cab093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp4.5\n",
    "common_index_data_rcp_4_5 = data_rcp_4_5.index.intersection(data_climate_reims_2009_2025.index)\n",
    "data_rcp_4_5_2009_2025 = data_rcp_4_5.loc[common_index_data_rcp_4_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8eb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp8.5\n",
    "common_index_data_rcp_8_5 = data_rcp_8_5.index.intersection(data_climate_reims_2009_2025.index)\n",
    "data_rcp_8_5_2009_2025 = data_rcp_8_5.loc[common_index_data_rcp_8_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d85183",
   "metadata": {},
   "source": [
    "#### **Dataset Prunay**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fcf226",
   "metadata": {},
   "source": [
    "##### **🌦️ Description des colonnes - Station météo Reims - Prunay**\n",
    "\n",
    "signification de chaque variable issue des données météorologiques :\n",
    "\n",
    "| **Nom de la colonne**             | **Description**                                                                 | **Unité**                   |\n",
    "|----------------------------------|----------------------------------------------------------------------------------|-----------------------------|\n",
    "| `time`                           | Horodatage des mesures                                                           | Date/Heure (ISO 8601)       |\n",
    "| `10m-U_wind_ms`                  | Composante est-ouest du vent à 10 mètres                                        | m/s                         |\n",
    "| `10m-V_wind_ms`                  | Composante nord-sud du vent à 10 mètres                                         | m/s                         |\n",
    "| `2m_DewPoint_Temperature_K`      | Température du point de rosée à 2 mètres                                        | Kelvin (K)                  |\n",
    "| `2m_Temperature_K`               | Température de l'air à 2 mètres                                                 | Kelvin (K)                  |\n",
    "| `Surface_Pressure_Pa`           | Pression atmosphérique au niveau de la surface                                  | Pascals (Pa)                |\n",
    "| `RH`                             | Humidité relative de l'air                                                       | Pourcentage (%)             |\n",
    "| `Wind_Speed`                     | Vitesse du vent calculée à partir des composantes U et V                        | m/s                         |\n",
    "| `Wind_Direction_CMEMS`           | Direction du vent (d'origine) selon les données CMEMS                           | Degrés (°)                  |\n",
    "| `Wind_Direction_Charbel`         | Direction du vent selon un calcul propre (ex. méthode \"Charbel\")                | Degrés (°)                  |\n",
    "| `Wind_Direction_Era5`            | Direction du vent selon les données ERA5 (réanalyse ECMWF)                      | Degrés (°)                  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8af2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay = pd.read_csv('Atmo\\donnees_Celine_LJ.csv')\n",
    "data_prunay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay['time'] = pd.to_datetime(data_prunay['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data_prunay.set_index('time', inplace=True)\n",
    "data_prunay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp2.6\n",
    "common_index_data_rcp_2_6 = data_rcp_2_6.index.intersection(data_prunay.index)\n",
    "data_rcp_2_6_ = data_rcp_2_6.loc[common_index_data_rcp_2_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp4.5\n",
    "common_index_data_rcp_4_5 = data_rcp_4_5.index.intersection(data_prunay.index)\n",
    "data_rcp_4_5_ = data_rcp_4_5.loc[common_index_data_rcp_4_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0856db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp8.5\n",
    "common_index_data_rcp_8_5 = data_rcp_8_5.index.intersection(data_prunay.index)\n",
    "data_rcp_8_5_ = data_rcp_8_5.loc[common_index_data_rcp_8_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.drop(['latitude', 'longitude'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae2efe",
   "metadata": {},
   "source": [
    "##### Correlation Barplot with meantemp feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91199a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "correlation_matrix = round(data_prunay.corr(), 2)\n",
    "\n",
    "correlation_with_trgt = correlation_matrix['2m_Temperature_K'].sort_values(ascending=False)\n",
    "\n",
    "ax = sns.barplot(x=correlation_with_trgt.index, y=correlation_with_trgt, palette='viridis')\n",
    "\n",
    "plt.title('Correlation with meantemp', size= 20)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b39b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay = data_prunay[[\"2m_Temperature_K\", \"RH\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d47ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay['2m_Temperature_C'] = data_prunay['2m_Temperature_K'] - 273.15\n",
    "data_prunay.drop(['2m_Temperature_K'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay = data_prunay.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_data_prunay, dl_val_data_prunay, dl_test_data_prunay = split_dataframe(data_prunay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdee804",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8de32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler_data_prunay = MinMaxScaler()  # scaler for humidity\n",
    "target_transformer_data_prunay = MinMaxScaler()   # scaler for target (meantemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a52cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_data_prunay['2m_Temperature_C'] = target_transformer_data_prunay.fit_transform(dl_train_data_prunay[['2m_Temperature_C']]) # target\n",
    "dl_train_data_prunay['RH'] = minmax_scaler_data_prunay.fit_transform(dl_train_data_prunay[['RH']]) # minmax for humidity\n",
    "\n",
    "dl_val_data_prunay['2m_Temperature_C'] = target_transformer_data_prunay.transform(dl_val_data_prunay[['2m_Temperature_C']])\n",
    "dl_val_data_prunay['RH'] = minmax_scaler_data_prunay.transform(dl_val_data_prunay[['RH']])\n",
    "\n",
    "dl_test_data_prunay['2m_Temperature_C'] = target_transformer_data_prunay.transform(dl_test_data_prunay[['2m_Temperature_C']])\n",
    "dl_test_data_prunay['RH'] = minmax_scaler_data_prunay.transform(dl_test_data_prunay[['RH']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f486dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "sequence_length = 3 # Example sequence length (adjust based on your data and experimentation)\n",
    "X_data_prunay_train, y_data_prunay_train = create_dataset(dl_train_data_prunay, dl_train_data_prunay['2m_Temperature_C'], sequence_length)\n",
    "X_data_prunay_val, y_data_prunay_val = create_dataset(dl_val_data_prunay, dl_val_data_prunay['2m_Temperature_C'], sequence_length)\n",
    "X_data_prunay_test, y_data_prunay_test = create_dataset(dl_test_data_prunay, dl_test_data_prunay['2m_Temperature_C'], sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ed35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_prunay, history_data_prunay, val_loss_data_prunay = build_and_train_bilstm(X_data_prunay_train, y_data_prunay_train, X_data_prunay_val, y_data_prunay_val, sequence_length , units=100, epochs=50, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19678dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_prunay.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation losses from history\n",
    "training_loss = history_data_prunay.history['loss']\n",
    "validation_loss = history_data_prunay.history['val_loss']\n",
    "\n",
    "# Plot loss values over epochs\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca93baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions data train\n",
    "y_pred_inv, y_val_inv = predict_and_inverse_transform(model_data_prunay, X_data_prunay_val, y_data_prunay_val, target_transformer_data_prunay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eavluate Model data train \n",
    "evaluate_model(y_val_inv, y_pred_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b26723",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33460bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "start = len(y_data_prunay_train) + sequence_length\n",
    "end = start + len(y_data_prunay_val)\n",
    "\n",
    "plt.plot(data_prunay.index[start:end], y_val_inv, label='True Values')\n",
    "plt.plot(data_prunay.index[start:end], y_pred_inv, label='Predictions', linestyle='dashed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Temperature')\n",
    "plt.title('Mean Temperature Predictions vs True Values (Data Validation)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dcd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions data test\n",
    "y_pred_inv_test, y_val_inv_test = predict_and_inverse_transform(model_data_prunay, X_data_prunay_test, y_data_prunay_test, target_transformer_data_prunay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eavluate Model data train \n",
    "evaluate_model(y_val_inv_test, y_pred_inv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des bornes d'index pour la partie test\n",
    "start_test = len(y_data_prunay_train) + len(y_data_prunay_val) + sequence_length\n",
    "end_test = start_test + len(y_data_prunay_test)\n",
    "\n",
    "# Tracé\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data_prunay.index[start_test:end_test], y_val_inv_test, label='True Values')\n",
    "plt.plot(data_prunay.index[start_test:end_test], y_pred_inv_test, label='Predictions', linestyle='dashed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Temperature')\n",
    "plt.title('Mean Temperature Predictions vs True Values (Data Test)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd1bb3",
   "metadata": {},
   "source": [
    "#### **Dataset Releve iButton Basilique Saint-Rémi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basilique_2018_2019 = pd.read_excel('Releve iButton Basilique Saint Rémi/DATA_processing_iButton_2018_2019.xlsx',  index_col='Date Heure', parse_dates=True)\n",
    "data_basilique_2018_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ede790",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,5))\n",
    "labels = data_basilique_2018_2019[Temp_HR].isnull().sum().sort_values(ascending=False).index.to_list()\n",
    "sizes = data_basilique_2018_2019[Temp_HR].isnull().sum().sort_values(ascending=False).to_list()\n",
    "sns.barplot(x=labels, y=sizes)\n",
    "plt.grid()\n",
    "plt.ylim((0.0, float(data_basilique_2018_2019.shape[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ef7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bsr_2018_2019 = data_basilique_2018_2019.resample('D').mean().copy()\n",
    "data_bsr_2018_2019 = data_bsr_2018_2019[[\"S2STemp\", \"S2SHR\"]]\n",
    "data_bsr_2018_2019 = data_bsr_2018_2019.interpolate(method='linear') ## Pour remplacer les valeurs NAN DU 2018-06-10, 2018-06-11, 2018-06-12, 2018-06-13\n",
    "data_bsr_2018_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_data_bsr, dl_val_data_bsr, dl_test_data_bsr = split_dataframe(data_bsr_2018_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler_data_bsr = MinMaxScaler()  # scaler for humidity\n",
    "target_transformer_data_bsr = MinMaxScaler()   # scaler for target (meantemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_data_bsr['S2STemp'] = target_transformer_data_bsr.fit_transform(dl_train_data_bsr[['S2STemp']]) # target\n",
    "dl_train_data_bsr['S2SHR'] = minmax_scaler_data_bsr.fit_transform(dl_train_data_bsr[['S2SHR']]) # minmax for humidity\n",
    "\n",
    "dl_val_data_bsr['S2STemp'] = target_transformer_data_bsr.transform(dl_val_data_bsr[['S2STemp']])\n",
    "dl_val_data_bsr['S2SHR'] = minmax_scaler_data_bsr.transform(dl_val_data_bsr[['S2SHR']])\n",
    "\n",
    "dl_test_data_bsr['S2STemp'] = target_transformer_data_bsr.transform(dl_test_data_bsr[['S2STemp']])\n",
    "dl_test_data_bsr['S2SHR'] = minmax_scaler_data_bsr.transform(dl_test_data_bsr[['S2SHR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "sequence_length = 3  # Example sequence length (adjust based on your data and experimentation)\n",
    "X_data_bsr_train, y_data_bsr_train = create_dataset(dl_train_data_bsr, dl_train_data_bsr['S2STemp'], sequence_length)\n",
    "X_data_bsr_val, y_data_bsr_val = create_dataset(dl_val_data_bsr, dl_val_data_bsr['S2STemp'], sequence_length)\n",
    "X_data_bsr_test, y_data_bsr_test = create_dataset(dl_test_data_bsr, dl_test_data_bsr['S2STemp'], sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_bsr, history_data_bsr, val_loss_data_bsr = build_and_train_bilstm(X_data_bsr_train, y_data_bsr_train, X_data_bsr_val, y_data_bsr_val, sequence_length , units=100, epochs=30, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe732fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_bsr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation losses from history\n",
    "training_loss = history_data_bsr.history['loss']\n",
    "validation_loss = history_data_bsr.history['val_loss']\n",
    "\n",
    "# Plot loss values over epochs\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions data train\n",
    "y_pred_data_bsr_inv, y_val_data_bsr_inv = predict_and_inverse_transform(model_data_bsr, X_data_bsr_val, y_data_bsr_val, target_transformer_data_bsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5bc540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eavluate Model data train \n",
    "evaluate_model(y_val_data_bsr_inv, y_pred_data_bsr_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'index de début et de fin pour la validation\n",
    "start_val = len(y_data_bsr_train) + sequence_length\n",
    "end_val = start_val + len(y_data_bsr_val)\n",
    "\n",
    "# Tracé\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data_bsr_2018_2019.index[start_val:end_val], y_val_data_bsr_inv, label='True Values')\n",
    "plt.plot(data_bsr_2018_2019.index[start_val:end_val], y_pred_data_bsr_inv, label='Predictions', linestyle='dashed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Temperature')\n",
    "plt.title('Mean Temperature Predictions vs True Values (Data Validation)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d17381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions data test\n",
    "y_pred_inv_data_bsr_test, y_test_inv_data_bsr_test = predict_and_inverse_transform(model_data_bsr, X_data_bsr_test, y_data_bsr_test, target_transformer_data_bsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eavluate Model data test\n",
    "evaluate_model(y_test_inv_data_bsr_test, y_pred_inv_data_bsr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des bornes d'index pour la partie test\n",
    "start_test = len(y_data_bsr_train) + len(y_data_bsr_val) + sequence_length\n",
    "end_test = start_test + len(y_data_bsr_test)\n",
    "\n",
    "# Tracé\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data_bsr_2018_2019.index[start_test:end_test], y_test_inv_data_bsr_test, label='True Values')\n",
    "plt.plot(data_bsr_2018_2019.index[start_test:end_test], y_pred_inv_data_bsr_test, label='Predictions', linestyle='dashed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Temperature')\n",
    "plt.title('Mean Temperature Predictions vs True Values (Data Test)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e622e1",
   "metadata": {},
   "source": [
    "#### **Correction des biais des données du DRIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61de8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mean_max_min(data_rcp_4_5_, data_prunay, \"Data DRIAS RCP 2.6\", \"Data Station Prunay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b0405",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e406310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des performances entre les RCP\n",
    "rcp_compare = {\n",
    "    'RCP 2.6': evaluate_model(data_prunay[\"2m_Temperature_C\"], data_rcp_2_6_[\"tasAdjust\"]),\n",
    "    'RCP 4.5': evaluate_model(data_prunay[\"2m_Temperature_C\"], data_rcp_4_5_[\"tasAdjust\"]),\n",
    "    'RCP 8.5': evaluate_model(data_prunay[\"2m_Temperature_C\"], data_rcp_8_5_[\"tasAdjust\"])\n",
    "}\n",
    "\n",
    "# Mettre dans un DataFrame avec MAE, RMSE, R2 en index\n",
    "rcp_compare = pd.DataFrame(rcp_compare, index=['MAE', 'RMSE', 'R2'])\n",
    "\n",
    "print()\n",
    "print()\n",
    "# Affichage clair\n",
    "print(rcp_compare.T.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasAdjust_corrected = quantile_mapping_correction(data_prunay[\"2m_Temperature_C\"], data_rcp_2_6[\"tasAdjust\"])\n",
    "data_rcp_2_6[\"tasAdjust\"] = tasAdjust_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da891e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp2.6\n",
    "common_index_data_rcp_2_6 = data_rcp_2_6.index.intersection(data_prunay.index)\n",
    "data_rcp_2_6_ = data_rcp_2_6.loc[common_index_data_rcp_2_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c1ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des performances entre les RCP\n",
    "rcp_compare = {\n",
    "    'RCP 2.6': evaluate_model(data_prunay[\"2m_Temperature_C\"], data_rcp_2_6_[\"tasAdjust\"]),\n",
    "}\n",
    "\n",
    "# Mettre dans un DataFrame avec MAE, RMSE, R2 en index\n",
    "rcp_compare = pd.DataFrame(rcp_compare, index=['MAE', 'RMSE', 'R2'])\n",
    "\n",
    "print()\n",
    "print()\n",
    "# Affichage clair\n",
    "print(rcp_compare.T.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mean_max_min(data_rcp_4_5_, data_prunay, \"Data DRIAS RCP 2.6\", \"Data Station Prunay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ba861",
   "metadata": {},
   "outputs": [],
   "source": [
    "RH = convertir_q_en_rh(data_rcp_2_6[\"hussAdjust\"], data_rcp_2_6[\"tasAdjust\"])\n",
    "data_rcp_2_6[\"RH\"] = RH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378375a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp2.6\n",
    "common_index_data_rcp_2_6 = data_rcp_2_6.index.intersection(data_prunay.index)\n",
    "data_rcp_2_6_ = data_rcp_2_6.loc[common_index_data_rcp_2_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc836499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des performances entre les RCP\n",
    "RH_compare = {\n",
    "    'RH': evaluate_model(data_prunay[\"RH\"], data_rcp_2_6_[\"RH\"]),\n",
    "}\n",
    "\n",
    "# Mettre dans un DataFrame avec MAE, RMSE, R2 en index\n",
    "rcp_compare = pd.DataFrame(RH_compare, index=['MAE', 'RMSE', 'R2'])\n",
    "\n",
    "print()\n",
    "print()\n",
    "# Affichage clair\n",
    "print(rcp_compare.T.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7949f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RH_corrected = quantile_mapping_correction(data_prunay[\"RH\"], data_rcp_2_6[\"RH\"])\n",
    "data_rcp_2_6[\"RH\"] = RH_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp2.6\n",
    "common_index_data_rcp_2_6 = data_rcp_2_6.index.intersection(data_prunay.index)\n",
    "data_rcp_2_6_ = data_rcp_2_6.loc[common_index_data_rcp_2_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bea9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des performances entre les RCP\n",
    "RH_compare = {\n",
    "    'RH': evaluate_model(data_prunay[\"RH\"], data_rcp_2_6_[\"RH\"]),\n",
    "}\n",
    "\n",
    "# Mettre dans un DataFrame avec MAE, RMSE, R2 en index\n",
    "rcp_compare = pd.DataFrame(RH_compare, index=['MAE', 'RMSE', 'R2'])\n",
    "\n",
    "print()\n",
    "print()\n",
    "# Affichage clair\n",
    "print(rcp_compare.T.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6 = data_rcp_2_6[[\"RH\", \"tasAdjust\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bed669",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6 = data_rcp_2_6.rename(columns={'tasAdjust': '2m_Temperature_C'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6['2m_Temperature_C'] = target_transformer_data_prunay.transform(data_rcp_2_6[['2m_Temperature_C']])\n",
    "data_rcp_2_6['RH'] = minmax_scaler_data_prunay.transform(data_rcp_2_6[['RH']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, time_steps=1): \n",
    "    Xs = []   \n",
    "    for i in range(len(X) - time_steps):   \n",
    "        v = X.iloc[i:(i + time_steps)].values \n",
    "        Xs.append(v)      \n",
    "    return np.array(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d23362",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "sequence_length = 3 # Example sequence length (adjust based on your data and experimentation)\n",
    "X = create_dataset(data_rcp_2_6, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb57ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20becdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction\n",
    "y_pred = model_data_prunay.predict(X)\n",
    "\n",
    "# Inversion de la transformation des prédictions\n",
    "y_pred_inv = target_transformer_data_prunay.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d561de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence_length\n",
    "start_idx = sequence_length\n",
    "end_idx = start_idx + len(y_pred_inv)\n",
    "\n",
    "# Tracé\n",
    "plt.figure(figsize=(30, 7))\n",
    "plt.plot(data_rcp_2_6.index[start_idx:end_idx], y_pred_inv, label='Predictions', linestyle='dashed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Temperature')\n",
    "plt.title('Mean Temperature Predictions (RCP 2.6)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0390182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence_length\n",
    "start_idx = sequence_length\n",
    "end_idx = start_idx + len(y_pred_inv)\n",
    "\n",
    "y_pred_flat = y_pred_inv.ravel()  \n",
    "\n",
    "# Créer le DataFrame\n",
    "df_prediction_rcp_2_6_corrige = pd.DataFrame({\n",
    "    'date': data_rcp_2_6.index[start_idx:end_idx],\n",
    "    'prediction': y_pred_flat\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_rcp_2_6_corrige.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ecaa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_rcp_2_6_corrige.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbfe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp2.6\n",
    "common_index_data_rcp_2_6 = df_prediction_rcp_2_6_corrige.index.intersection(data_prunay.index)\n",
    "data_rcp_2_6_ = df_prediction_rcp_2_6_corrige.loc[common_index_data_rcp_2_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28e3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay[\"2m_Temperature_C\"][common_index_data_rcp_2_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb746b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des performances entre les RCP\n",
    "rcp_compare = {\n",
    "    'RCP 2.6': evaluate_model(data_prunay[\"2m_Temperature_C\"][common_index_data_rcp_2_6], data_rcp_2_6_[\"prediction\"]),\n",
    "}\n",
    "\n",
    "# Mettre dans un DataFrame avec MAE, RMSE, R2 en index\n",
    "rcp_compare = pd.DataFrame(rcp_compare, index=['MAE', 'RMSE', 'R2'])\n",
    "\n",
    "print()\n",
    "print()\n",
    "# Affichage clair\n",
    "print(rcp_compare.T.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8475493",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_ = data_rcp_2_6.rename(columns={'prediction': 'tasAdjust'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbf208",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay = data_prunay.rename(columns={'tasAdjust': '2m_Temperature_C'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e28c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mean_max_min(data_rcp_4_5_, data_prunay, \"Data DRIAS RCP 2.6 Corrigé\", \"Data Station Prunay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db9f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_rcp_2_6_corrige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8104aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_data_bsr_linear, dl_val_data_bsr_linear, dl_test_data_prunay_bsr_linear = split_dataframe(data_prunay, 0.8, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_model, linear_regression_prédictions, linear_regression_history  = build_and_train_linear(\n",
    "    X = df_prediction_rcp_2_6_corrige[\"prediction\"],\n",
    "    y = data_bsr_2018_2019[\"S2STemp\"],\n",
    "    années_entrainement = ('2018', '2019'),\n",
    "    epochs = 50,\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4201fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(linear_regression_history.history['loss'], label='Loss')\n",
    "plt.plot(linear_regression_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Courbe de l'erreur pendant l'entraînement\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results Data Validation\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data_bsr_2018_2019.index[len(y_data_bsr_train): len(y_data_bsr_train) + len(y_data_bsr_val)], y_val_data_bsr_inv, label='True Values')\n",
    "plt.plot(data_bsr_2018_2019.index[len(y_data_bsr_train): len(y_data_bsr_train) + len(y_data_bsr_val)], y_pred_data_bsr_inv, label='Predictions', linestyle='dashed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Temperature')\n",
    "plt.title('Mean Temperature Predictions vs True Values (Data Validation)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19666552",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_prédictions = df = pd.DataFrame({'2m_Temperature_C': linear_regression_prédictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28df4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mean_max_min(data_rcp_4_5_, linear_regression_prédictions, \"Data DRIAS RCP 2.6 Corrigé\", \"Saint-Remy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eef02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee140c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_each_year_separately(data_prunay[\"2m_Temperature_C\"], data_climate_reims_2009_2025[\"MEAN_TEMPERATURE_C\"], \"Station Prunay\", \"Historique-Météo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ed671",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_climate_reims_2009_2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_climate_reims_2009_2025.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f333dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les index communs data rcp2.6\n",
    "common_index_data_prunay_historique_meteo = data_climate_reims_2009_2025.index.intersection(data_prunay.index)\n",
    "data_climate_reims_2009_2025_ = data_climate_reims_2009_2025.loc[common_index_data_prunay_historique_meteo]\n",
    "data_prunay_ = data_prunay.loc[common_index_data_prunay_historique_meteo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f82d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(data_prunay_[\"2m_Temperature_C\"], data_climate_reims_2009_2025_[\"MEAN_TEMPERATURE_C\"]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay = pd.read_csv('Atmo\\donnees_Celine_LJ.csv')\n",
    "data_prunay['time'] = pd.to_datetime(data_prunay['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data_prunay.set_index('time', inplace=True)\n",
    "data_prunay['2m_Temperature_C'] = data_prunay['2m_Temperature_K'] - 273.15\n",
    "\n",
    "# Détermine le nombre de lignes nécessaires pour les subplots\n",
    "rows = len(tour_sud_2_temp)\n",
    "cols = 2  # Deux colonnes : une pour data_1, une pour data_2\n",
    "\n",
    "# Copie des bases de données pour éviter de modifier les originales\n",
    "data_copy_1 = data_basilique_2018_2019.copy()\n",
    "data_copy_2 = data_prunay.copy()\n",
    "\n",
    "# Suppression des doublons pour éviter des erreurs d'affichage ou d'analyse\n",
    "data_copy_1 = data_copy_1[~data_copy_1.index.duplicated()]\n",
    "\n",
    "# Filtrage des données pour ne conserver que les années 2018 et 2019\n",
    "data_copy_1 = data_copy_1[data_copy_1.index.year.isin([2018, 2019])]\n",
    "\n",
    "i = 1  # Compteur pour positionner les subplots\n",
    "\n",
    "# Définition de la taille de la figure pour un affichage correct des graphiques\n",
    "plt.figure(figsize=(25, 4 * rows))\n",
    "\n",
    "for column in tour_sud_2_temp:\n",
    "\n",
    "    # Tracé du premier subplot : données brutes de data_1\n",
    "    plt.subplot(rows, cols, i)\n",
    "    plt.scatter(data_copy_1[column].index, data_copy_1[column].values, c=\"grey\")\n",
    "    plt.ylim(-10, 50)\n",
    "    plt.title(f\"Original Data {designations[column]}: {column}\")\n",
    "    plt.grid()\n",
    "\n",
    "    # Tracé du deuxième subplot : données de la station Prunay\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.scatter(data_copy_2.loc[data_copy_2.index.year.isin([2018, 2019]), \"2m_Temperature_C\"].index, data_copy_2.loc[data_copy_2.index.year.isin([2018, 2019]), \"2m_Temperature_C\"].values, c=\"grey\")\n",
    "    # plt.ylim(data_copy_1[column].min()-5.0, data_copy_1[column].max()+5.0)\n",
    "    plt.title(\"Station Prunay\")\n",
    "    plt.grid()\n",
    "\n",
    "    # Incrémentation du compteur pour passer au subplot suivant\n",
    "    i += 2\n",
    "\n",
    "# Ajustement automatique de l'affichage des graphiques pour éviter les chevauchements\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f8814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
