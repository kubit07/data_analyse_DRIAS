{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc598c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import joblib\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Layer, Conv1D, MaxPooling1D, Flatten, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.interpolate import interp1d\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, train_size=0.7, val_size=0.2):\n",
    "    \"\"\"\n",
    "    D√©coupe un DataFrame temporel en trois parties : train, val, test,\n",
    "    en respectant l'ordre chronologique.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Donn√©es √† d√©couper (index√© ou non par le temps)\n",
    "        train_size (float): Proportion pour l'ensemble d'entra√Ænement\n",
    "        val_size (float): Proportion pour la validation\n",
    "\n",
    "    Returns:\n",
    "        df_train, df_val, df_test (DataFrames)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    n = len(df)\n",
    "    train_end = int(n * train_size)\n",
    "    val_end = int(n * (train_size + val_size))\n",
    "\n",
    "    df_train = df.iloc[:train_end]\n",
    "    df_val = df.iloc[train_end:val_end]\n",
    "    df_test = df.iloc[val_end:]\n",
    "\n",
    "    print(f\"Train size : {len(df_train)}\")\n",
    "    print(f\"Val size : {len(df_val)}\")\n",
    "    print(f\"Test size : {len(df_test)}\")\n",
    "\n",
    "    return df_train.copy(), df_val.copy(), df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcule et affiche les m√©triques MAE, RMSE et R¬≤ entre les vraies valeurs et les pr√©dictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): Valeurs r√©elles.\n",
    "        y_pred (array-like): Valeurs pr√©dites.\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f'MAE: {mae:.4f}')\n",
    "    print(f'RMSE: {rmse:.4f}')\n",
    "    print(f'R2 Score: {r2:.4f}')\n",
    "\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2 Score\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfde327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "    \"\"\"\n",
    "This function prepares the input features and target values in the format required for training a recurrent neural network (RNN) or LSTM model for sequential prediction tasks. It creates sequences of input features and their corresponding target values, which can be fed into the model during training.\n",
    "\n",
    "    - X: This parameter represents the input features, typically a pandas DataFrame containing multiple time-series variables such as temperature, humidity, etc.\n",
    "    - y: This parameter represents the target values, which are typically the values we want to predict based on the input features.\n",
    "    - time_steps: This parameter defines the length of each sequence. It determines how many data points from the past will be used to predict the next data point. For example, if time_steps is set to 3, the function will create sequences of three consecutive data points as input features and the next data point as the target value.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_temperature_model(X, y, epochs=100, batch_size=32, validation_split=0.2):\n",
    "    \"\"\"\n",
    "    Construit, compile et entra√Æne un mod√®le Keras pour pr√©dire 24 temp√©ratures horaires.\n",
    "\n",
    "    Param√®tres\n",
    "    ----------\n",
    "    X : ndarray shape (n_samples, n_features)\n",
    "        Tableau des caract√©ristiques d‚Äôentr√©e (ex. Tmin, Tmoy, Tmax, jour_annee, mois).\n",
    "    y : ndarray shape (n_samples, n_outputs)\n",
    "        Tableau des cibles (24 temp√©ratures horaires).\n",
    "    epochs : int, optional (default=100)\n",
    "        Nombre d‚Äô√©poques d‚Äôentra√Ænement.\n",
    "    batch_size : int, optional (default=32)\n",
    "        Taille du batch.\n",
    "    validation_split : float, optional (default=0.2)\n",
    "        Fraction des donn√©es r√©serv√©e √† la validation.\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    model : keras.Model\n",
    "        Le mod√®le entra√Æn√©.\n",
    "    history : keras.callbacks.History\n",
    "        L‚Äôhistorique d‚Äôentra√Ænement (pertes et m√©triques).\n",
    "    \"\"\"\n",
    "    input_dim = X.shape[1]\n",
    "    output_dim = y.shape[1]\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        # r√©gression, donc pas d‚Äôactivation finale\n",
    "        Dense(output_dim)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    history = model.fit(X, y,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=validation_split,\n",
    "                        verbose=1)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_drias(path_fichier_excel):\n",
    "    \"\"\"\n",
    "    Charge un fichier Excel DRIAS avec une colonne 'Date' au format '%d/%m/%Y',\n",
    "    et retourne un DataFrame avec la date en index.\n",
    "\n",
    "    Args:\n",
    "        path_fichier_excel (str): Chemin vers le fichier Excel.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Donn√©es DRIAS avec l'index dat√©.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(path_fichier_excel)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "    df.set_index('Date', inplace=True)\n",
    "    display(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74498686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_inverse_transform(model, X, y, target_transformer):\n",
    "    \"\"\"\n",
    "    Effectue la pr√©diction avec le mod√®le donn√© et applique l'inverse de la transformation \n",
    "    sur les pr√©dictions et les vraies valeurs cibles.\n",
    "\n",
    "    Args:\n",
    "        model: Mod√®le entra√Æn√© (ex. BiLSTM).\n",
    "        X_val: Donn√©es d'entr√©e de validation.\n",
    "        y_val: Vraies valeurs cibles de validation.\n",
    "        target_transformer: Transformateur utilis√© pour normaliser les cibles (ex. MinMaxScaler).\n",
    "\n",
    "    Returns:\n",
    "        Tuple (y_pred_original_scale, y_true_original_scale)\n",
    "    \"\"\"\n",
    "    # Pr√©diction\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Inversion de la transformation des pr√©dictions\n",
    "    y_pred_inv = target_transformer.inverse_transform(y_pred)\n",
    "\n",
    "    # Reshape puis inversion de la transformation des vraies valeurs\n",
    "    y = y.reshape(-1, 1)\n",
    "    y_val_inv = target_transformer.inverse_transform(y)\n",
    "\n",
    "    return y_pred_inv, y_val_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_q_en_rh(q_kgkg, temperature_C, pression_hPa=1013.25):\n",
    "    \"\"\"\n",
    "    Convertit une s√©rie d'humidit√© sp√©cifique (kg/kg) et de temp√©rature (¬∞C)\n",
    "    en humidit√© relative (%) en supposant une pression constante.\n",
    "\n",
    "    Param√®tres :\n",
    "        q_kgkg : pd.Series ou np.array d'humidit√© sp√©cifique (kg/kg)\n",
    "        temperature_C : pd.Series ou np.array de temp√©rature (¬∞C)\n",
    "        pression_hPa : pression atmosph√©rique en hPa (par d√©faut = 1013.25)\n",
    "\n",
    "    Retour :\n",
    "        pd.Series ou np.array d'humidit√© relative (%) ‚Äî m√™me type que l'entr√©e\n",
    "    \"\"\"\n",
    "    q = np.asarray(q_kgkg)\n",
    "    T = np.asarray(temperature_C)\n",
    "\n",
    "    # Pression partielle de vapeur d'eau (e) [hPa]\n",
    "    e = (q * pression_hPa) / (0.622 + 0.378 * q)\n",
    "\n",
    "    # Pression de vapeur saturante (e_s) [hPa] ‚Äî formule de Tetens\n",
    "    e_s = 6.112 * np.exp((17.67 * T) / (T + 243.5))\n",
    "\n",
    "    # Humidit√© relative RH [%]\n",
    "    RH = 100 * e / e_s\n",
    "    RH = np.clip(RH, 0, 100)\n",
    "\n",
    "    # Renvoyer dans le m√™me format que l'entr√©e\n",
    "    if isinstance(q_kgkg, pd.Series):\n",
    "        return pd.Series(RH, index=q_kgkg.index, name='RH_%')\n",
    "    else:\n",
    "        return RH\n",
    "\n",
    "\n",
    "def calculate_relative_humidity(tmean, huss):\n",
    "    \"\"\"\n",
    "    Calcule l'humidit√© relative (hr) en % √† partir des donn√©es :\n",
    "    - tasmin : temp√©rature minimale journali√®re √† 2m (¬∞C)\n",
    "    - tasmax : temp√©rature maximale journali√®re √† 2m (¬∞C)\n",
    "    - huss   : humidit√© sp√©cifique √† 2m (g/kg)\n",
    "\n",
    "    Toutes les entr√©es peuvent √™tre scalaires, des tableaux NumPy ou des colonnes pandas.\n",
    "    \"\"\"\n",
    "\n",
    "    # 2. Pression de vapeur de saturation psat (en hPa)\n",
    "    psat = np.where(\n",
    "        tmean < 0,\n",
    "        10 ** (2.7862 + (9.7561 * tmean) / (272.67 + tmean)),\n",
    "        10 ** (2.7862 + (7.5526 * tmean) / (239.21 + tmean))\n",
    "    )\n",
    "\n",
    "    # 3. Calcul de l‚Äôhumidit√© relative en pourcentage\n",
    "    hr = (huss / 0.622) / psat * 10000\n",
    "    hr = np.minimum(hr, 100)  # Limiter √† 100 %\n",
    "\n",
    "    return hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f802e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_humidite_kgkg_en_gkg(serie_kgkg):\n",
    "    \"\"\"\n",
    "    Convertit une s√©rie Pandas d'humidit√© sp√©cifique de kg/kg en g/kg.\n",
    "\n",
    "    Param√®tres :\n",
    "    - serie_kgkg : pd.Series contenant des valeurs en kg/kg\n",
    "\n",
    "    Retour :\n",
    "    - pd.Series contenant les valeurs converties en g/kg\n",
    "    \"\"\"\n",
    "    return serie_kgkg * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182fe4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_24h_values(group):\n",
    "    if len(group) == 24:\n",
    "        return group.values\n",
    "    else:\n",
    "        print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7482c51",
   "metadata": {},
   "source": [
    "##### **Dataset DRIAS RCP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6 = load_data_drias(\n",
    "    'Drias/CNRM-CERFACS-CNRM-CM5_CNRM-ALADIN63_rcp2.6_METEO-FRANCE_ADAMONT-France_SAFRAN_day_2006_2100.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5326178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_4_5 = load_data_drias(\n",
    "    'Drias/CNRM-CERFACS-CNRM-CM5_CNRM-ALADIN63_rcp4.5_METEO-FRANCE_ADAMONT-France_SAFRAN_day_2006_2100.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9365446",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_8_5 = load_data_drias(\n",
    "    'Drias/CNRM-CERFACS-CNRM-CM5_CNRM-ALADIN63_rcp8.5_METEO-FRANCE_ADAMONT-France_SAFRAN_day_2006_2100.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3948e8",
   "metadata": {},
   "source": [
    "##### **Dataset Prunay**\n",
    "üå¶Ô∏è Description des colonnes - Station m√©t√©o Reims - Prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay = pd.read_csv('Atmo/reims_hourly_2007_2025.csv')\n",
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36bb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay['time'] = pd.to_datetime(\n",
    "    data_prunay['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data_prunay.set_index('time', inplace=True)\n",
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r√©cup√©rer les index communs data rcp2.6\n",
    "common_index_data_rcp_2_6 = data_rcp_2_6.index.intersection(data_prunay.index)\n",
    "data_rcp_2_6_ = data_rcp_2_6.loc[common_index_data_rcp_2_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66029edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r√©cup√©rer les index communs data rcp4.5\n",
    "common_index_data_rcp_4_5 = data_rcp_4_5.index.intersection(data_prunay.index)\n",
    "data_rcp_4_5_ = data_rcp_4_5.loc[common_index_data_rcp_4_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a909d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r√©cup√©rer les index communs data rcp8.5\n",
    "common_index_data_rcp_8_5 = data_rcp_8_5.index.intersection(data_prunay.index)\n",
    "data_rcp_8_5_ = data_rcp_8_5.loc[common_index_data_rcp_8_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay = data_prunay[[\"temperature_2m\",\n",
    "                           \"relative_humidity_2m\", \"precipitation\"]].copy()\n",
    "data_prunay.rename(columns={\"relative_humidity_2m\": \"prunay_RH\"}, inplace=True)\n",
    "data_prunay.rename(\n",
    "    columns={\"temperature_2m\": \"prunay_Temperature\"}, inplace=True)\n",
    "data_prunay.rename(\n",
    "    columns={\"precipitation\": \"prunay_Precipitation\"}, inplace=True)\n",
    "data_prunay = data_prunay[~data_prunay.index.duplicated(keep='first')]\n",
    "data_prunay.dropna(inplace=True)\n",
    "RH = convertir_q_en_rh(data_rcp_2_6[\"hussAdjust\"], data_rcp_2_6[\"tasAdjust\"])\n",
    "data_rcp_2_6[\"rcp_RH\"] = RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2abbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_predict = data_prunay.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e85ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf065c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_temp_predict = data_prunay_hourly_predict[\"prunay_Temperature\"].copy(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_hr_predict = data_prunay_hourly_predict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40bb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_temp_predict = data_prunay_hourly_temp_predict.resample(\n",
    "    'D').agg(['min', 'mean', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_hr_predict = data_prunay_hourly_hr_predict.resample('D').agg({\n",
    "    'prunay_RH': ['mean'],\n",
    "    'prunay_Temperature': ['min', 'mean', 'max'],\n",
    "    'prunay_Precipitation': ['mean']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e241286",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_hr_predict.columns = ['{}_{}'.format(\n",
    "    col[0], col[1]) for col in data_prunay_hourly_hr_predict.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403bbca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_temp_predict[\"day_of_year\"] = data_prunay_hourly_temp_predict.index.dayofyear\n",
    "data_prunay_hourly_temp_predict[\"month\"] = data_prunay_hourly_temp_predict.index.month\n",
    "data_prunay_hourly_temp_predict[\"hour\"] = data_prunay_hourly_temp_predict.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a48df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_hr_predict[\"day_of_year\"] = data_prunay_hourly_hr_predict.index.dayofyear\n",
    "data_prunay_hourly_hr_predict[\"month\"] = data_prunay_hourly_hr_predict.index.month\n",
    "data_prunay_hourly_hr_predict[\"hour\"] = data_prunay_hourly_hr_predict.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149551bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_hr_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0465593",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_temp_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f379e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = data_prunay[\"prunay_Temperature\"].resample(\n",
    "    'D').apply(extract_24h_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698cd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rh = data_prunay[\"prunay_RH\"].resample('D').apply(extract_24h_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_temp_predict[\"y\"] = y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_hr_predict[\"y\"] = y_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b58f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_temp_predict.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10023b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_hr_predict.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_temp_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay_hourly_hr_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d218f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, features, pred):\n",
    "    # Transformation cyclique pour les caract√©ristiques temporelles\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "    # Cible - conversion en matrice 2D (n_jours √ó 24_heures)\n",
    "    y = np.vstack(df['y'].values)\n",
    "\n",
    "    # Normalisation\n",
    "    if pred == \"temp\":\n",
    "        X_scaler = StandardScaler()\n",
    "        y_scaler = StandardScaler()\n",
    "\n",
    "    if pred == \"hr\":\n",
    "        X_scaler = StandardScaler()\n",
    "        y_scaler = MinMaxScaler()\n",
    "\n",
    "    X = X_scaler.fit_transform(df[features])\n",
    "    y = y_scaler.fit_transform(y)\n",
    "\n",
    "    return X, y, X_scaler, y_scaler, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhRange(Layer):\n",
    "    def __init__(self, min_val=0, max_val=100, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "\n",
    "    def call(self, inputs):\n",
    "        tanh = tf.tanh(inputs)  # [-1, 1]\n",
    "        scaled = (tanh + 1) / 2  # [0, 1]\n",
    "        return scaled * (self.max_val - self.min_val) + self.min_val\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"min_val\": self.min_val,\n",
    "            \"max_val\": self.max_val\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "def build_model(input_dim, pred):\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu',\n",
    "              kernel_initializer='he_normal',\n",
    "              kernel_regularizer=l2(0.001),\n",
    "              input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(128, activation='relu',\n",
    "              kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(24),  # 24 sorties pour les donn√©es horaires\n",
    "    ])\n",
    "\n",
    "    if pred == \"hr\":\n",
    "        # Couche personnalis√©e ajout√©e ici\n",
    "        model.add(TanhRange(min_val=0, max_val=100))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.001, clipvalue=0.5)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement avec validation temporelle\n",
    "def train_model(X, y, pred):\n",
    "    # S√©paration temporelle (plus adapt√©e pour les donn√©es chronologiques)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(tscv.split(X)):\n",
    "        print(f\"\\nEntra√Ænement fold {fold+1}/{tscv.get_n_splits()}\")\n",
    "        print(\n",
    "            f\"Taille train: {len(train_index)}, validation: {len(val_index)}\")\n",
    "\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        model = build_model(X.shape[1], pred)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=10, restore_best_weights=True,\n",
    "                          monitor='val_loss'),\n",
    "            ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)\n",
    "        ]\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,\n",
    "            batch_size=16,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Sauvegarder le meilleur mod√®le\n",
    "        val_loss = min(history.history['val_loss'])\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model\n",
    "            print(f\"Nouveau meilleur mod√®le avec val_loss = {val_loss:.4f}\")\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed9b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, y_scaler, pred):\n",
    "    # D√©normalisation\n",
    "    y_test_actual = y_scaler.inverse_transform(y_test)\n",
    "    y_pred = y_scaler.inverse_transform(model.predict(X_test))\n",
    "\n",
    "    # Calcul MAE par heure\n",
    "    hourly_mae = np.mean(np.abs(y_pred - y_test_actual), axis=0)\n",
    "\n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # MAE par heure\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(24), hourly_mae, color='skyblue')\n",
    "    plt.title('Mean Absolute Error (MAE) per hour')\n",
    "    plt.xlabel('Hour of the day')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xticks(range(24), [f'{h:02d}h' for h in range(24)], rotation=45)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Comparaison sur un √©chantillon\n",
    "    sample_idx = np.random.randint(len(X_test))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(y_test_actual[sample_idx], 'o-', label='true value', linewidth=2)\n",
    "    plt.plot(y_pred[sample_idx], 's-', label='Prediction', linewidth=1.5)\n",
    "    plt.title(f'Prediction vs True value - Random Day')\n",
    "    plt.xlabel('Hours')\n",
    "    plt.ylabel(\"Temp (¬∞C)\" if pred == \"temp\" else \"HR (%)\")\n",
    "    plt.legend()\n",
    "    plt.xticks(range(0, 24, 3), [f'{h:02d}h' for h in range(0, 24, 3)])\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_evaluation.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    if pred == \"temp\":\n",
    "        print(f\"\\nModel performance:\")\n",
    "        print(f\"Mean MAE: {np.mean(hourly_mae):.4f}¬∞C\")\n",
    "        print(\n",
    "            f\"Max MAE (at {np.argmax(hourly_mae):02d}h): {np.max(hourly_mae):.4f}¬∞C\")\n",
    "        print(\n",
    "            f\"Min MAE (at {np.argmin(hourly_mae):02d}h): {np.min(hourly_mae):.4f}¬∞C\")\n",
    "    if pred == \"hr\":\n",
    "        print(f\"\\nModel performance:\")\n",
    "        print(f\"Mean MAE: {np.mean(hourly_mae):.4f}%\")\n",
    "        print(\n",
    "            f\"Max MAE (at {np.argmax(hourly_mae):02d}h): {np.max(hourly_mae):.4f}%\")\n",
    "        print(\n",
    "            f\"Min MAE (at {np.argmin(hourly_mae):02d}h): {np.min(hourly_mae):.4f}%\")\n",
    "\n",
    "    return hourly_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model_temporal_split(X, y, y_scaler, train_model, evaluate_model, test_size=0.2, pred=\"temp\"):\n",
    "    \"\"\"\n",
    "    Entra√Æne et √©value un mod√®le de pr√©diction de temp√©rature avec validation temporelle\n",
    "\n",
    "    Args:\n",
    "        X (np.array): Features normalis√©es\n",
    "        y (np.array): Cibles normalis√©es \n",
    "        y_scaler (StandardScaler): Scaler pour la d√©normalisation des cibles\n",
    "        test_size (float): Proportion des donn√©es √† utiliser pour le test (0.0-1.0)\n",
    "\n",
    "    Returns:\n",
    "        model (keras.Model): Mod√®le entra√Æn√©\n",
    "        hourly_mae (np.array): MAE par heure sur l'ensemble de test\n",
    "    \"\"\"\n",
    "    # S√©paration train/test temporelle\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "    print(\"\\nS√©paration des donn√©es:\")\n",
    "    print(f\"Train: {X_train.shape[0]} √©chantillons\")\n",
    "    print(f\"Test: {X_test.shape[0]} √©chantillons\")\n",
    "\n",
    "    # Entra√Ænement\n",
    "    print(\"\\nD√©but de l'entra√Ænement du mod√®le...\")\n",
    "    model = train_model(X_train, y_train, pred)\n",
    "\n",
    "    # √âvaluation\n",
    "    print(\"\\n√âvaluation sur l'ensemble de test...\")\n",
    "    hourly_mae = evaluate_model(model, X_test, y_test, y_scaler, pred)\n",
    "\n",
    "    return model, hourly_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc8ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, y_temp, X_scaler_temp, y_scaler_temp, features_temp = preprocess_data(\n",
    "    data_prunay_hourly_temp_predict, ['min', 'max', 'mean', 'day_sin', 'day_cos', 'month_sin', 'month_cos'], pred=\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8893f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hr, y_hr, X_scaler_hr, y_scaler_hr, features_hr = preprocess_data(data_prunay_hourly_hr_predict, [\n",
    "                                                                    'prunay_RH_mean', 'prunay_Temperature_min', 'prunay_Temperature_max', 'prunay_Temperature_mean', 'prunay_Precipitation_mean', 'day_sin', 'day_cos', 'month_sin', 'month_cos'], pred=\"hr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54903563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_temp, hourly_mae_temp = train_and_evaluate_model_temporal_split(\n",
    "    X_temp, y_temp, y_scaler_temp, train_model=train_model, evaluate_model=evaluate_model, pred=\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0be826",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hr, hourly_mae_hr = train_and_evaluate_model_temporal_split(X_hr, y_hr, y_scaler_hr, train_model=train_model, evaluate_model=evaluate_model, pred=\"hr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b311c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_day_stats(temps_array):\n",
    "    return {\n",
    "        'min_temp': float(np.min(temps_array)),\n",
    "        'max_temp': float(np.max(temps_array)),\n",
    "        'mean_temp': float(np.mean(temps_array)),\n",
    "        'day_of_year': temps_array.index.dayofyear[0],\n",
    "        'month': temps_array.index.month[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658c6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de pr√©diction\n",
    "def predict_hourly_temperatures(min_temp, max_temp, mean_temp, day_of_year, month, model, X_scaler, y_scaler):\n",
    "    # Pr√©paration de l'input\n",
    "    day_sin = np.sin(2 * np.pi * day_of_year / 365.25)\n",
    "    day_cos = np.cos(2 * np.pi * day_of_year / 365.25)\n",
    "    month_sin = np.sin(2 * np.pi * month / 12)\n",
    "    month_cos = np.cos(2 * np.pi * month / 12)\n",
    "\n",
    "    input_data = np.array([[min_temp, max_temp, mean_temp,\n",
    "                            day_sin, day_cos, month_sin, month_cos]])\n",
    "\n",
    "    # Transformation\n",
    "    scaled_input = X_scaler.transform(input_data)\n",
    "    prediction = model.predict(scaled_input)\n",
    "    return y_scaler.inverse_transform(prediction)[0]\n",
    "\n",
    "\n",
    "# Exemple de pr√©diction\n",
    "print(\"\\nExemple de pr√©diction...\")\n",
    "\n",
    "new_day = {\n",
    "    'min_temp': 0.1,\n",
    "    'max_temp': 3.0,\n",
    "    'mean_temp': 1.5125,\n",
    "    'day_of_year': 32,\n",
    "    'month': 2\n",
    "}\n",
    "\n",
    "predictions = predict_hourly_temperatures(new_day[\"min_temp\"], new_day[\"max_temp\"], new_day[\"mean_temp\"],\n",
    "                                          new_day[\"day_of_year\"], new_day[\"month\"], model_temp, X_scaler_temp, y_scaler_temp)\n",
    "\n",
    "# Visualisation de la pr√©diction\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(predictions, 'o-', color='darkorange', linewidth=2)\n",
    "# plt.plot(data_prunay.loc[\"2015-02-01\"][\"prunay_Temperature\"].values, 'o-', color='red', linewidth=2)\n",
    "plt.title(\n",
    "    f\"Pr√©diction de temp√©rature - Jour {new_day['day_of_year']} (Mois {new_day['month']})\")\n",
    "plt.xlabel('Heure de la journ√©e')\n",
    "plt.ylabel('Temp√©rature (¬∞C)')\n",
    "plt.xticks(range(24), [f'{h:02d}h' for h in range(24)], rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_example.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab44ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_day_stats(data_prunay.loc[\"2015-02-01\"][\"prunay_Temperature\"])\n",
    "data_prunay.loc[\"2015-02-01\"][\"prunay_Temperature\"].index.dayofyear[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc213d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.loc[\"2015-02-01\"][\"prunay_Temperature\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48012f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_day_stats(data_prunay.loc[\"2015-02-01\"][\"prunay_RH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ab425",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_day_stats(data_prunay.loc[\"2015-02-01\"][\"prunay_Precipitation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_hourly_temperatures(new_day[\"min_temp\"], new_day[\"max_temp\"], new_day[\"mean_temp\"],\n",
    "                            new_day[\"day_of_year\"], new_day[\"month\"], model_temp, X_scaler_temp, y_scaler_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb976a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hourly_hr(prunay_RH_mean, prunay_Temperature_min, prunay_Temperature_max, prunay_Temperature_mean, prunay_Precipitation_mean, day_of_year, month, model, X_scaler, y_scaler):\n",
    "    # Pr√©paration de l'input\n",
    "    day_sin = np.sin(2 * np.pi * day_of_year / 365.25)\n",
    "    day_cos = np.cos(2 * np.pi * day_of_year / 365.25)\n",
    "    month_sin = np.sin(2 * np.pi * month / 12)\n",
    "    month_cos = np.cos(2 * np.pi * month / 12)\n",
    "\n",
    "    input_data = np.array([[prunay_RH_mean, prunay_Temperature_min, prunay_Temperature_max, prunay_Temperature_mean, prunay_Precipitation_mean,\n",
    "                            day_sin, day_cos, month_sin, month_cos]])\n",
    "\n",
    "    # Transformation\n",
    "    scaled_input = X_scaler.transform(input_data)\n",
    "    prediction = model.predict(scaled_input)\n",
    "    return y_scaler.inverse_transform(prediction)[0]\n",
    "\n",
    "\n",
    "# Exemple de pr√©diction\n",
    "print(\"\\nExemple de pr√©diction...\")\n",
    "\n",
    "\n",
    "new_day = {\n",
    "    # humidit√© moyenne journali√®re (%)\n",
    "    'prunay_RH_mean': 81.29166666666667,\n",
    "    'prunay_Temperature_min': 1.0,\n",
    "    'prunay_Temperature_max': 5.9,\n",
    "    'prunay_Temperature_mean': 3.591,\n",
    "    'prunay_Precipitation_mean': 0.0625,\n",
    "    'day_of_year': 325,\n",
    "    'month': 11,\n",
    "}\n",
    "\n",
    "predictions = predict_hourly_hr(new_day[\"prunay_RH_mean\"], new_day[\"prunay_Temperature_min\"], new_day[\"prunay_Temperature_max\"],\n",
    "                                new_day[\"prunay_Temperature_mean\"], new_day[\"prunay_Precipitation_mean\"], new_day[\"day_of_year\"], new_day[\"month\"], model_hr, X_scaler_hr, y_scaler_hr)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(predictions, 'o-', color='teal', linewidth=2)\n",
    "plt.title(\n",
    "    f\"Pr√©diction de l'humidit√© - Jour {new_day['day_of_year']} (Mois {new_day['month']})\")\n",
    "plt.xlabel('Heure de la journ√©e')\n",
    "plt.ylabel(\"Humidit√© (%)\")\n",
    "plt.xticks(range(24), [f'{h:02d}h' for h in range(24)], rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_humidity_example.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee18505",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.loc[\"2007-02-01\"].resample('D').agg(['min', 'mean', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.loc[\"2024-11-20\"][\"prunay_RH\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_day_stats(data_prunay.loc[\"2024-11-20\"][\"prunay_RH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94aa66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_day_stats(data_prunay.loc[\"2024-11-20\"][\"prunay_Temperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5410e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_day_stats(data_prunay.loc[\"2024-11-20\"][\"prunay_Precipitation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.loc[\"2008-07-01\"][\"prunay_RH\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a026cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44247b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.loc[\"2008-07-01\"][\"prunay_RH\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90801a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75db39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.loc[\"2007-02-01\"][\"prunay_RH\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1d15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_day_stats(data_prunay.loc[\"2007-07-01\"][\"prunay_Temperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff3d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_day_stats(data_prunay.loc[\"2007-07-01\"][\"prunay_RH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_day_stats(data_prunay.loc[\"2007-07-01\"][\"prunay_Precipitation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd54a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_dataframe_temp(df_input, model, X_scaler, y_scaler):\n",
    "\n",
    "    # Copie pour √©viter d'alt√©rer le DataFrame d'origine\n",
    "    df = df_input.copy()\n",
    "\n",
    "    # Ajout des features cycliques\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "    # Features\n",
    "    features = ['min', 'max', 'mean',\n",
    "                'day_sin', 'day_cos', 'month_sin', 'month_cos']\n",
    "\n",
    "    # Normalisation\n",
    "    X = X_scaler.transform(df[features])\n",
    "\n",
    "    # Pr√©diction\n",
    "    y_pred_scaled = model.predict(X)\n",
    "\n",
    "    # Retour √† l'√©chelle originale\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # Ajout dans le DataFrame sous forme de listes\n",
    "    df['y_pred'] = [list(row) for row in y_pred]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee91f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_dataframe_hr(df_input, model, X_scaler, y_scaler):\n",
    "\n",
    "    # Copie pour √©viter d'alt√©rer le DataFrame d'origine\n",
    "    df = df_input.copy()\n",
    "\n",
    "    # Ajout des features cycliques\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "    # Features\n",
    "    features = ['prunay_RH_mean', 'prunay_Temperature_min', 'prunay_Temperature_max', 'prunay_Temperature_mean', 'prunay_Precipitation_mean',\n",
    "                'day_sin', 'day_cos', 'month_sin', 'month_cos']\n",
    "\n",
    "    # Normalisation\n",
    "    X = X_scaler.transform(df[features])\n",
    "\n",
    "    # Pr√©diction\n",
    "    y_pred_scaled = model.predict(X)\n",
    "\n",
    "    # Retour √† l'√©chelle originale\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # Ajout dans le DataFrame sous forme de listes\n",
    "    df['y_pred'] = [list(row) for row in y_pred]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_temp = data_rcp_2_6[[\n",
    "    'tasminAdjust', 'tasmaxAdjust', 'tasAdjust']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_hr = data_rcp_2_6[[\n",
    "    'rcp_RH', 'tasminAdjust', 'tasmaxAdjust', 'tasAdjust', 'prtotAdjust']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1b1526",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2cf3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_temp.rename(\n",
    "    columns={\"tasminAdjust\": \"min\", \"tasmaxAdjust\": \"max\", \"tasAdjust\": \"mean\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_hr.rename(columns={\"rcp_RH\": \"prunay_RH_mean\", \"tasminAdjust\": \"prunay_Temperature_min\",\n",
    "                                     \"tasmaxAdjust\": \"prunay_Temperature_max\", \"tasAdjust\": \"prunay_Temperature_mean\", \"prtotAdjust\": \"prunay_Precipitation_mean\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b16f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_temp[\"day_of_year\"] = data_rcp_2_6predict_hourly_temp.index.dayofyear\n",
    "data_rcp_2_6predict_hourly_temp[\"month\"] = data_rcp_2_6predict_hourly_temp.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4aa7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_hr[\"day_of_year\"] = data_rcp_2_6predict_hourly_hr.index.dayofyear\n",
    "data_rcp_2_6predict_hourly_hr[\"month\"] = data_rcp_2_6predict_hourly_hr.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_temp = predict_from_dataframe_temp(\n",
    "    data_rcp_2_6predict_hourly_temp, model=model_temp, X_scaler=X_scaler_temp, y_scaler=y_scaler_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e040fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_hr = predict_from_dataframe_hr(\n",
    "    data_rcp_2_6predict_hourly_hr, model=model_hr, X_scaler=X_scaler_hr, y_scaler=y_scaler_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6predict_hourly_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac8c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_temp = data_rcp_2_6predict_hourly_temp[[\"y_pred\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_hr = data_rcp_2_6predict_hourly_hr[[\"y_pred\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_to_hourly(df, value_col=\"y\"):\n",
    "    \"\"\"\n",
    "    Transforme un DataFrame journalier (1 ligne = 1 jour, 1 cellule = 24 valeurs)\n",
    "    en DataFrame horaire (1 ligne = 1 heure).\n",
    "\n",
    "    Param√®tres :\n",
    "    ------------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame journalier, index = dates, colonne = listes de 24 valeurs horaires.\n",
    "    value_col : str\n",
    "        Nom de la colonne contenant les valeurs horaires.\n",
    "\n",
    "    Retour :\n",
    "    --------\n",
    "    df_hourly : pd.DataFrame\n",
    "        DataFrame horaire, index = datetime (jour + heure), colonnes : ['y']\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Assurer que l‚Äôindex est de type datetime\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # R√©p√©ter chaque ligne 24 fois\n",
    "    df_expanded = df.loc[df.index.repeat(24)].copy()\n",
    "\n",
    "    # Aplatir les valeurs horaires\n",
    "    df_expanded[value_col] = df[value_col].explode().values\n",
    "\n",
    "    # Ajouter les heures (0 √† 23)\n",
    "    df_expanded[\"hour\"] = list(range(24)) * len(df)\n",
    "\n",
    "    # Cr√©er l‚Äôindex horaire\n",
    "    df_expanded[\"datetime\"] = df_expanded.index + \\\n",
    "        pd.to_timedelta(df_expanded[\"hour\"], unit='h')\n",
    "\n",
    "    # Finaliser\n",
    "    df_hourly = df_expanded[[\"datetime\", value_col]\n",
    "                            ].set_index(\"datetime\").sort_index()\n",
    "\n",
    "    return df_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_temp = daily_to_hourly(df_hourly_temp, \"y_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6862b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_hr = daily_to_hourly(df_hourly_hr, \"y_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700bc9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pourcentages_par_intervalles(array):\n",
    "    array = np.array(array)\n",
    "    total = len(array)\n",
    "\n",
    "    pct_0_30 = np.sum((array >= 0) & (array < 30)) / total * 100\n",
    "    pct_30_50 = np.sum((array >= 30) & (array < 50)) / total * 100\n",
    "    pct_50_70 = np.sum((array >= 50) & (array < 70)) / total * 100\n",
    "    pct_70_90 = np.sum((array >= 70) & (array < 90)) / total * 100\n",
    "    pct_90_100 = np.sum((array >= 90) & (array < 100)) / total * 100\n",
    "    pct_eq_100 = np.sum(array == 100) / total * 100\n",
    "    pct_sup_100 = np.sum(array > 100) / total * 100\n",
    "\n",
    "    return {\n",
    "        '0‚Äì30%': pct_0_30,\n",
    "        '30‚Äì50%': pct_30_50,\n",
    "        '50‚Äì70%': pct_50_70,\n",
    "        '70‚Äì90%': pct_70_90,\n",
    "        '90‚Äì100%': pct_90_100,\n",
    "        '==100%': pct_eq_100,\n",
    "        '>100%': pct_sup_100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff37458",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "correlation_matrix = round(data_rcp_2_6.select_dtypes('number').corr(), 2)\n",
    "\n",
    "correlation_with_trgt = correlation_matrix['rcp_RH'].sort_values(\n",
    "    ascending=False)\n",
    "\n",
    "ax = sns.barplot(x=correlation_with_trgt.index,\n",
    "                 y=correlation_with_trgt, palette='viridis')\n",
    "\n",
    "plt.title('Correlation with meantemp', size=20)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pourcentages_par_intervalles(df_hourly_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99572ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pourcentages_par_intervalles(data_prunay[\"prunay_RH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_hourly_hr > 100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070038fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_hr[df_hourly_hr >= 100] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f87628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd662ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ac304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_temp.rename(columns={\"y_pred\": \"rcp_2_6_Temperature\"}, inplace=True)\n",
    "df_hourly_hr.rename(columns={\"y_pred\": \"rcp_2_6_RH\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3220769",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_hourly_temp_hr = pd.concat([df_hourly_temp, df_hourly_hr], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa291e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_hourly_temp_hr.loc[\"2024-07\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay[data_prunay[\"prunay_Temperature\"] < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay.loc[\"2024-07\", [\"prunay_Temperature\", \"prunay_RH\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bb898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_hourly_temp_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87056af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_hourly_temp_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afefe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prunay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7da24",
   "metadata": {},
   "source": [
    "#### **LSTM**\n",
    "\n",
    "Bidirectional LSTMs are an extension of traditional LSTMs that can improve model performance on sequence classification problems.\n",
    "\n",
    "In problems where all timesteps of the input sequence are available, Bidirectional LSTMs train two instead of one LSTMs on the input sequence. The first on the input sequence as-is and the second on a reversed copy of the input sequence. This can provide additional context to the network and result in faster and even fuller learning on the problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r√©cup√©rer les index communs data rcp2.6\n",
    "common_index_data_rcp_2_6 = data_rcp_2_6_hourly_temp_hr.index.intersection(\n",
    "    data_prunay.index)\n",
    "data_rcp_2_6_hourly_temp_hr_ = data_rcp_2_6_hourly_temp_hr.loc[common_index_data_rcp_2_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c917e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_hourly_temp_hr_[\n",
    "    \"prunay_Temperature\"] = data_prunay[\"prunay_Temperature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_hourly_temp_hr_[\"prunay_RH\"] = data_prunay[\"prunay_RH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23061a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_hourly_temp_hr_predict_temp = data_rcp_2_6_hourly_temp_hr_[\n",
    "    ['rcp_2_6_Temperature', 'rcp_2_6_RH', 'prunay_Temperature']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4057008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_hourly_temp_hr_predict_hr = data_rcp_2_6_hourly_temp_hr_[\n",
    "    ['rcp_2_6_Temperature', 'rcp_2_6_RH', 'prunay_RH']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rcp_2_6_hourly_temp_hr_predict_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres du mod√®le\n",
    "WINDOW_SIZE = 48 # Fen√™tre de 24 heures (ajustable)\n",
    "PREDICTION_HORIZON = 1  # Pr√©dire l'heure suivante\n",
    "TEST_SIZE = 0.2  # 20% pour le test\n",
    "\n",
    "# Features et target\n",
    "FEATURES = ['rcp_2_6_Temperature', 'rcp_2_6_RH']\n",
    "TARGET = 'prunay_RH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59369932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des donn√©es\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Scaling des features\n",
    "X_scaled = scaler_X.fit_transform(\n",
    "    data_rcp_2_6_hourly_temp_hr_predict_hr[FEATURES])\n",
    "# Scaling de la target\n",
    "y_scaled = scaler_y.fit_transform(\n",
    "    data_rcp_2_6_hourly_temp_hr_predict_hr[[TARGET]])\n",
    "\n",
    "# Cr√©ation des s√©quences pour LSTM\n",
    "\n",
    "\n",
    "def create_sequences(X, y, window_size, prediction_horizon):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - window_size - prediction_horizon + 1):\n",
    "        X_seq.append(X[i:(i + window_size)])\n",
    "        y_seq.append(y[i + window_size + prediction_horizon - 1])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "\n",
    "X_sequences, y_sequences = create_sequences(\n",
    "    X_scaled, y_scaled, WINDOW_SIZE, PREDICTION_HORIZON)\n",
    "\n",
    "print(f\"Forme des s√©quences X: {X_sequences.shape}\")\n",
    "print(f\"Forme des s√©quences y: {y_sequences.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division train/test\n",
    "split_idx = int(len(X_sequences) * (1 - TEST_SIZE))\n",
    "\n",
    "X_train = X_sequences[:split_idx]\n",
    "X_test = X_sequences[split_idx:]\n",
    "y_train = y_sequences[:split_idx]\n",
    "y_test = y_sequences[split_idx:]\n",
    "\n",
    "print(f\"Train shapes: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
    "print(f\"Test shapes: X_test {X_test.shape}, y_test {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c21957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=input_shape, \n",
    "         kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    LSTM(64, return_sequences=True, \n",
    "         kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    LSTM(32, return_sequences=False,\n",
    "         kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "    model.compile(\n",
    "        # optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Construction du mod√®le\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (window_size, n_features)\n",
    "model = build_lstm_model(input_shape)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48154951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=10, factor=0.5)\n",
    "]\n",
    "\n",
    "# Entra√Ænement\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93721412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_true = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# R√©cup√©ration des dates pour le test set\n",
    "dates = data_rcp_2_6_hourly_temp_hr_predict_hr.index[WINDOW_SIZE +\n",
    "                                                       PREDICTION_HORIZON - 1:]\n",
    "test_dates = dates[split_idx:split_idx + len(X_test)]\n",
    "\n",
    "# M√©triques\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "print(f\"MAE: {mae:.2f} %\")\n",
    "print(f\"RMSE: {rmse:.2f} %\")\n",
    "\n",
    "# Visualisation des r√©sultats\n",
    "plt.figure(figsize=(40, 5))\n",
    "\n",
    "# Courbes de pr√©diction\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(test_dates[:5000], y_true[:5000], label='Trues Values', alpha=0.7)\n",
    "plt.plot(test_dates[:5000], y_pred[:5000], label='Predictions', alpha=0.7)\n",
    "plt.title('Predictions vs Trues Values')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Humidity (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f934653",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_rcp_2_6_data_bias_correction = data_rcp_2_6_hourly_temp_hr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dataframe_temperature(df, temp_col, rh_col, model, scaler_X, scaler_y, window_size):\n",
    "    temps = df[temp_col].values\n",
    "    rh = df[rh_col].values\n",
    "    X = np.column_stack([temps, rh])\n",
    "\n",
    "    # mise √† l'√©chelle\n",
    "    X_scaled = scaler_X.transform(X)\n",
    "\n",
    "    # construction des s√©quences\n",
    "    sequences = []\n",
    "    for i in range(len(X_scaled) - window_size + 1):\n",
    "        sequences.append(X_scaled[i:i + window_size])\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "\n",
    "    # pr√©diction\n",
    "    y_scaled = model.predict(sequences, verbose=0)\n",
    "    y_pred = scaler_y.inverse_transform(y_scaled).flatten()\n",
    "\n",
    "    # alignement des pr√©dictions avec df\n",
    "    preds = np.full(len(df), np.nan)\n",
    "    preds[window_size - 1:] = y_pred\n",
    "    df['predicted_hr'] = preds\n",
    "    return df\n",
    "\n",
    "\n",
    "# Utilisation avec votre DataFrame\n",
    "temp_rcp_2_6_data_bias_correction_ = predict_dataframe_temperature(\n",
    "    df=temp_rcp_2_6_data_bias_correction,\n",
    "    temp_col=\"rcp_2_6_Temperature\",\n",
    "    rh_col=\"rcp_2_6_RH\",\n",
    "    model=model,\n",
    "    scaler_X=scaler_X,\n",
    "    scaler_y=scaler_y,\n",
    "    window_size=WINDOW_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04182aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_2_6_data_bias_correction_Temp = pd.read_csv('temp_rcp_2_6_data_bias_correction_csv_Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d59d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_2_6_data_bias_correction_HR = pd.read_csv('temp_rcp_2_6_data_bias_correction_HR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc09af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_2_6_data_bias_correction_Temp.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887d9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_2_6_data_bias_correction_HR.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9645c42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rcp_2_6_Temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rcp_2_6_RH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "predicted_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "predicted_hr",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c105bbe6-f3c6-4636-992a-5ea70ea9706e",
       "rows": [
        [
         "2006-01-01 00:00:00",
         "-1.2194412",
         "92.831665",
         null,
         null
        ],
        [
         "2006-01-01 01:00:00",
         "-1.4633898",
         "93.72783",
         null,
         null
        ],
        [
         "2006-01-01 02:00:00",
         "-1.7336789",
         "94.44652",
         null,
         null
        ],
        [
         "2006-01-01 03:00:00",
         "-2.0068758",
         "95.01584",
         null,
         null
        ],
        [
         "2006-01-01 04:00:00",
         "-2.330127",
         "95.3068",
         null,
         null
        ],
        [
         "2006-01-01 05:00:00",
         "-2.2904096",
         "95.08014",
         null,
         null
        ],
        [
         "2006-01-01 06:00:00",
         "-2.49746",
         "95.136116",
         null,
         null
        ],
        [
         "2006-01-01 07:00:00",
         "-2.457099",
         "95.69187",
         null,
         null
        ],
        [
         "2006-01-01 08:00:00",
         "-2.3561003",
         "95.4361",
         null,
         null
        ],
        [
         "2006-01-01 09:00:00",
         "-2.361168",
         "98.12616",
         null,
         null
        ],
        [
         "2006-01-01 10:00:00",
         "-1.8991824",
         "97.113304",
         null,
         null
        ],
        [
         "2006-01-01 11:00:00",
         "-0.663345",
         "95.32881",
         null,
         null
        ],
        [
         "2006-01-01 12:00:00",
         "0.77032995",
         "92.13161",
         null,
         null
        ],
        [
         "2006-01-01 13:00:00",
         "2.1102123",
         "88.73108",
         null,
         null
        ],
        [
         "2006-01-01 14:00:00",
         "3.3737173",
         "85.647545",
         null,
         null
        ],
        [
         "2006-01-01 15:00:00",
         "3.9675317",
         "84.07371",
         null,
         null
        ],
        [
         "2006-01-01 16:00:00",
         "4.3362803",
         "83.22534",
         null,
         null
        ],
        [
         "2006-01-01 17:00:00",
         "4.101826",
         "83.4685",
         null,
         null
        ],
        [
         "2006-01-01 18:00:00",
         "3.2441716",
         "86.490395",
         null,
         null
        ],
        [
         "2006-01-01 19:00:00",
         "2.295763",
         "89.38195",
         null,
         null
        ],
        [
         "2006-01-01 20:00:00",
         "1.9175262",
         "91.54681",
         null,
         null
        ],
        [
         "2006-01-01 21:00:00",
         "1.214525",
         "94.296616",
         null,
         null
        ],
        [
         "2006-01-01 22:00:00",
         "1.0648773",
         "95.170235",
         null,
         null
        ],
        [
         "2006-01-01 23:00:00",
         "0.67719805",
         "94.94433",
         null,
         null
        ],
        [
         "2006-01-02 00:00:00",
         "2.1303914",
         "32.6856",
         null,
         null
        ],
        [
         "2006-01-02 01:00:00",
         "2.0631726",
         "32.95745",
         null,
         null
        ],
        [
         "2006-01-02 02:00:00",
         "1.840432",
         "36.350002",
         null,
         null
        ],
        [
         "2006-01-02 03:00:00",
         "1.6420262",
         "38.927937",
         null,
         null
        ],
        [
         "2006-01-02 04:00:00",
         "1.5327985",
         "36.414898",
         null,
         null
        ],
        [
         "2006-01-02 05:00:00",
         "1.4245254",
         "31.444042",
         null,
         null
        ],
        [
         "2006-01-02 06:00:00",
         "1.3725033",
         "30.201557",
         null,
         null
        ],
        [
         "2006-01-02 07:00:00",
         "1.271718",
         "30.356052",
         null,
         null
        ],
        [
         "2006-01-02 08:00:00",
         "1.2149187",
         "30.115513",
         null,
         null
        ],
        [
         "2006-01-02 09:00:00",
         "1.4830313",
         "37.32599",
         null,
         null
        ],
        [
         "2006-01-02 10:00:00",
         "1.4154567",
         "33.628338",
         null,
         null
        ],
        [
         "2006-01-02 11:00:00",
         "1.8571209",
         "31.930534",
         null,
         null
        ],
        [
         "2006-01-02 12:00:00",
         "2.5683522",
         "27.76937",
         null,
         null
        ],
        [
         "2006-01-02 13:00:00",
         "3.2910528",
         "26.165197",
         null,
         null
        ],
        [
         "2006-01-02 14:00:00",
         "3.8800077",
         "19.450634",
         null,
         null
        ],
        [
         "2006-01-02 15:00:00",
         "4.1536136",
         "17.524078",
         null,
         null
        ],
        [
         "2006-01-02 16:00:00",
         "4.3566384",
         "17.551437",
         null,
         null
        ],
        [
         "2006-01-02 17:00:00",
         "4.0359187",
         "17.888811",
         null,
         null
        ],
        [
         "2006-01-02 18:00:00",
         "3.584909",
         "18.680807",
         null,
         null
        ],
        [
         "2006-01-02 19:00:00",
         "3.1967793",
         "21.707077",
         null,
         null
        ],
        [
         "2006-01-02 20:00:00",
         "2.8255262",
         "25.738142",
         null,
         null
        ],
        [
         "2006-01-02 21:00:00",
         "2.6781127",
         "27.172155",
         null,
         null
        ],
        [
         "2006-01-02 22:00:00",
         "2.4050338",
         "30.817179",
         null,
         null
        ],
        [
         "2006-01-02 23:00:00",
         "2.289459",
         "31.553566",
         "84.01976776123047",
         "84.01976776123047"
        ],
        [
         "2006-01-03 00:00:00",
         "8.836995",
         "94.53372",
         "83.60246276855469",
         "83.60246276855469"
        ],
        [
         "2006-01-03 01:00:00",
         "8.952434",
         "94.91702",
         "83.10662841796875",
         "83.10662841796875"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 832752
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rcp_2_6_Temperature</th>\n",
       "      <th>rcp_2_6_RH</th>\n",
       "      <th>predicted_temp</th>\n",
       "      <th>predicted_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:00:00</th>\n",
       "      <td>-1.2</td>\n",
       "      <td>92.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 01:00:00</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>93.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 02:00:00</th>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 03:00:00</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 04:00:00</th>\n",
       "      <td>-2.3</td>\n",
       "      <td>95.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 19:00:00</th>\n",
       "      <td>1.7</td>\n",
       "      <td>85.2</td>\n",
       "      <td>84.5</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 20:00:00</th>\n",
       "      <td>1.5</td>\n",
       "      <td>86.2</td>\n",
       "      <td>85.8</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 21:00:00</th>\n",
       "      <td>1.2</td>\n",
       "      <td>88.8</td>\n",
       "      <td>86.5</td>\n",
       "      <td>86.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 22:00:00</th>\n",
       "      <td>0.9</td>\n",
       "      <td>90.7</td>\n",
       "      <td>86.7</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 23:00:00</th>\n",
       "      <td>0.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832752 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rcp_2_6_Temperature  rcp_2_6_RH  predicted_temp  \\\n",
       "datetime                                                               \n",
       "2006-01-01 00:00:00                 -1.2        92.8             NaN   \n",
       "2006-01-01 01:00:00                 -1.5        93.7             NaN   \n",
       "2006-01-01 02:00:00                 -1.7        94.4             NaN   \n",
       "2006-01-01 03:00:00                 -2.0        95.0             NaN   \n",
       "2006-01-01 04:00:00                 -2.3        95.3             NaN   \n",
       "...                                  ...         ...             ...   \n",
       "2100-12-31 19:00:00                  1.7        85.2            84.5   \n",
       "2100-12-31 20:00:00                  1.5        86.2            85.8   \n",
       "2100-12-31 21:00:00                  1.2        88.8            86.5   \n",
       "2100-12-31 22:00:00                  0.9        90.7            86.7   \n",
       "2100-12-31 23:00:00                  0.7        90.0            87.0   \n",
       "\n",
       "                     predicted_hr  \n",
       "datetime                           \n",
       "2006-01-01 00:00:00           NaN  \n",
       "2006-01-01 01:00:00           NaN  \n",
       "2006-01-01 02:00:00           NaN  \n",
       "2006-01-01 03:00:00           NaN  \n",
       "2006-01-01 04:00:00           NaN  \n",
       "...                           ...  \n",
       "2100-12-31 19:00:00          84.5  \n",
       "2100-12-31 20:00:00          85.8  \n",
       "2100-12-31 21:00:00          86.5  \n",
       "2100-12-31 22:00:00          86.7  \n",
       "2100-12-31 23:00:00          87.0  \n",
       "\n",
       "[832752 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcp_2_6_data_bias_correction_HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fed9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_2_6_data_bias_correction_Temp_HR = pd.DataFrame(index=rcp_2_6_data_bias_correction_Temp.index.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56525c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_2_6_data_bias_correction_Temp_HR[\"predicted_temp\"] = rcp_2_6_data_bias_correction_Temp[\"predicted_temp\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aeff8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_2_6_data_bias_correction_Temp_HR[\"predicted_hr\"] = rcp_2_6_data_bias_correction_HR[\"predicted_hr\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace73faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_2_6_data_bias_correction_Temp_HR.index = pd.to_datetime(rcp_2_6_data_bias_correction_Temp_HR.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f5125db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "predicted_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "predicted_hr",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "61688f9b-3f6d-4192-986d-a439b553e3f8",
       "rows": [
        [
         "2006-01-01 00:00:00",
         null,
         null
        ],
        [
         "2006-01-01 01:00:00",
         null,
         null
        ],
        [
         "2006-01-01 02:00:00",
         null,
         null
        ],
        [
         "2006-01-01 03:00:00",
         null,
         null
        ],
        [
         "2006-01-01 04:00:00",
         null,
         null
        ],
        [
         "2006-01-01 05:00:00",
         null,
         null
        ],
        [
         "2006-01-01 06:00:00",
         null,
         null
        ],
        [
         "2006-01-01 07:00:00",
         null,
         null
        ],
        [
         "2006-01-01 08:00:00",
         null,
         null
        ],
        [
         "2006-01-01 09:00:00",
         null,
         null
        ],
        [
         "2006-01-01 10:00:00",
         null,
         null
        ],
        [
         "2006-01-01 11:00:00",
         null,
         null
        ],
        [
         "2006-01-01 12:00:00",
         null,
         null
        ],
        [
         "2006-01-01 13:00:00",
         null,
         null
        ],
        [
         "2006-01-01 14:00:00",
         null,
         null
        ],
        [
         "2006-01-01 15:00:00",
         null,
         null
        ],
        [
         "2006-01-01 16:00:00",
         null,
         null
        ],
        [
         "2006-01-01 17:00:00",
         null,
         null
        ],
        [
         "2006-01-01 18:00:00",
         null,
         null
        ],
        [
         "2006-01-01 19:00:00",
         null,
         null
        ],
        [
         "2006-01-01 20:00:00",
         null,
         null
        ],
        [
         "2006-01-01 21:00:00",
         null,
         null
        ],
        [
         "2006-01-01 22:00:00",
         null,
         null
        ],
        [
         "2006-01-01 23:00:00",
         null,
         null
        ],
        [
         "2006-01-02 00:00:00",
         null,
         null
        ],
        [
         "2006-01-02 01:00:00",
         null,
         null
        ],
        [
         "2006-01-02 02:00:00",
         null,
         null
        ],
        [
         "2006-01-02 03:00:00",
         null,
         null
        ],
        [
         "2006-01-02 04:00:00",
         null,
         null
        ],
        [
         "2006-01-02 05:00:00",
         null,
         null
        ],
        [
         "2006-01-02 06:00:00",
         null,
         null
        ],
        [
         "2006-01-02 07:00:00",
         null,
         null
        ],
        [
         "2006-01-02 08:00:00",
         null,
         null
        ],
        [
         "2006-01-02 09:00:00",
         null,
         null
        ],
        [
         "2006-01-02 10:00:00",
         null,
         null
        ],
        [
         "2006-01-02 11:00:00",
         null,
         null
        ],
        [
         "2006-01-02 12:00:00",
         null,
         null
        ],
        [
         "2006-01-02 13:00:00",
         null,
         null
        ],
        [
         "2006-01-02 14:00:00",
         null,
         null
        ],
        [
         "2006-01-02 15:00:00",
         null,
         null
        ],
        [
         "2006-01-02 16:00:00",
         null,
         null
        ],
        [
         "2006-01-02 17:00:00",
         null,
         null
        ],
        [
         "2006-01-02 18:00:00",
         null,
         null
        ],
        [
         "2006-01-02 19:00:00",
         null,
         null
        ],
        [
         "2006-01-02 20:00:00",
         null,
         null
        ],
        [
         "2006-01-02 21:00:00",
         null,
         null
        ],
        [
         "2006-01-02 22:00:00",
         null,
         null
        ],
        [
         "2006-01-02 23:00:00",
         "4.733339309692383",
         "84.01976776123047"
        ],
        [
         "2006-01-03 00:00:00",
         "4.863122940063477",
         "83.60246276855469"
        ],
        [
         "2006-01-03 01:00:00",
         "5.281907558441162",
         "83.10662841796875"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 832752
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_temp</th>\n",
       "      <th>predicted_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 01:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 19:00:00</th>\n",
       "      <td>5.6</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 20:00:00</th>\n",
       "      <td>5.1</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 21:00:00</th>\n",
       "      <td>4.8</td>\n",
       "      <td>86.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 22:00:00</th>\n",
       "      <td>4.5</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31 23:00:00</th>\n",
       "      <td>4.2</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832752 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     predicted_temp  predicted_hr\n",
       "datetime                                         \n",
       "2006-01-01 00:00:00             NaN           NaN\n",
       "2006-01-01 01:00:00             NaN           NaN\n",
       "2006-01-01 02:00:00             NaN           NaN\n",
       "2006-01-01 03:00:00             NaN           NaN\n",
       "2006-01-01 04:00:00             NaN           NaN\n",
       "...                             ...           ...\n",
       "2100-12-31 19:00:00             5.6          84.5\n",
       "2100-12-31 20:00:00             5.1          85.8\n",
       "2100-12-31 21:00:00             4.8          86.5\n",
       "2100-12-31 22:00:00             4.5          86.7\n",
       "2100-12-31 23:00:00             4.2          87.0\n",
       "\n",
       "[832752 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcp_2_6_data_bias_correction_Temp_HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9971eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basilique = pd.read_excel('Releves/DATA_processing_iButton_2018_2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a7281b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basilique.set_index('Date Heure', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "673aee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_basilique.index = data_basilique.index.round('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45bc9616",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basilique = data_basilique[['N2OTemp', 'S2OHR']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016980bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r√©cup√©rer les index communs data rcp8.5\n",
    "common_index_data_basilique_rcp_2_6_data_bias_correction_Temp_HR = rcp_2_6_data_bias_correction_Temp_HR.index.intersection(data_basilique.index)\n",
    "rcp_2_6_data_bias_correction_Temp_HR_ = rcp_2_6_data_bias_correction_Temp_HR.loc[common_index_data_basilique_rcp_2_6_data_bias_correction_Temp_HR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4691e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_2_6_data_bias_correction_Temp_HR_[\"N2OTemp\"] = data_basilique[\"N2OTemp\"].copy()\n",
    "rcp_2_6_data_bias_correction_Temp_HR_[\"S2OHR\"] = data_basilique[\"S2OHR\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbef9f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Date Heure",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "predicted_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "predicted_hr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "N2OTemp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S2OHR",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ca683159-e06f-4b3f-b15a-6de0c43e3bf6",
       "rows": [
        [
         "2018-01-01 00:00:01",
         null,
         null,
         "9.7",
         "82.8"
        ],
        [
         "2018-01-01 01:00:01",
         null,
         null,
         "9.0",
         "92.2"
        ],
        [
         "2018-01-01 02:00:01",
         null,
         null,
         "8.9",
         "80.8"
        ],
        [
         "2018-01-01 03:00:01",
         null,
         null,
         "8.8",
         "79.4"
        ],
        [
         "2018-01-01 04:00:01",
         null,
         null,
         "8.0",
         "87.6"
        ],
        [
         "2018-01-01 05:00:01",
         null,
         null,
         "7.7",
         "82.4"
        ],
        [
         "2018-01-01 06:00:01",
         null,
         null,
         "7.4",
         "84.5"
        ],
        [
         "2018-01-01 07:00:01",
         null,
         null,
         "7.4",
         "85.2"
        ],
        [
         "2018-01-01 08:00:01",
         null,
         null,
         "7.2",
         "84.9"
        ],
        [
         "2018-01-01 09:00:01",
         null,
         null,
         "7.3",
         "85.7"
        ],
        [
         "2018-01-01 10:00:01",
         null,
         null,
         "7.4",
         "87.7"
        ],
        [
         "2018-01-01 11:00:01",
         null,
         null,
         "7.9",
         "86.7"
        ],
        [
         "2018-01-01 12:00:01",
         null,
         null,
         "6.7",
         "100.4"
        ],
        [
         "2018-01-01 13:00:01",
         null,
         null,
         "5.4",
         "104.8"
        ],
        [
         "2018-01-01 14:00:01",
         null,
         null,
         "6.3",
         "105.0"
        ],
        [
         "2018-01-01 15:00:01",
         null,
         null,
         "7.0",
         "105.2"
        ],
        [
         "2018-01-01 16:00:01",
         null,
         null,
         "7.8",
         "105.6"
        ],
        [
         "2018-01-01 17:00:01",
         null,
         null,
         "7.5",
         "104.4"
        ],
        [
         "2018-01-01 18:00:01",
         null,
         null,
         "7.3",
         "105.2"
        ],
        [
         "2018-01-01 19:00:01",
         null,
         null,
         "6.8",
         "106.2"
        ],
        [
         "2018-01-01 20:00:01",
         null,
         null,
         "6.7",
         "102.3"
        ],
        [
         "2018-01-01 21:00:01",
         null,
         null,
         "6.3",
         "99.7"
        ],
        [
         "2018-01-01 22:00:01",
         null,
         null,
         "6.0",
         "102.4"
        ],
        [
         "2018-01-01 23:00:01",
         null,
         null,
         "6.0",
         "99.8"
        ],
        [
         "2018-01-02 00:00:01",
         null,
         null,
         "6.1",
         "95.1"
        ],
        [
         "2018-01-02 01:00:01",
         null,
         null,
         "6.4",
         "92.9"
        ],
        [
         "2018-01-02 02:00:01",
         null,
         null,
         "6.4",
         "93.2"
        ],
        [
         "2018-01-02 03:00:01",
         null,
         null,
         "6.7",
         "92.3"
        ],
        [
         "2018-01-02 04:00:01",
         null,
         null,
         "6.3",
         "93.8"
        ],
        [
         "2018-01-02 05:00:01",
         null,
         null,
         "5.8",
         "93.7"
        ],
        [
         "2018-01-02 06:00:01",
         null,
         null,
         "6.2",
         "94.1"
        ],
        [
         "2018-01-02 07:00:01",
         null,
         null,
         "5.6",
         "96.2"
        ],
        [
         "2018-01-02 08:00:01",
         null,
         null,
         "5.5",
         "94.8"
        ],
        [
         "2018-01-02 09:00:01",
         null,
         null,
         "5.7",
         "95.5"
        ],
        [
         "2018-01-02 10:00:01",
         null,
         null,
         "6.3",
         "95.3"
        ],
        [
         "2018-01-02 11:00:01",
         null,
         null,
         "6.8",
         "96.2"
        ],
        [
         "2018-01-02 12:00:01",
         null,
         null,
         "6.9",
         "94.8"
        ],
        [
         "2018-01-02 13:00:01",
         null,
         null,
         "7.3",
         "92.9"
        ],
        [
         "2018-01-02 14:00:01",
         null,
         null,
         "7.2",
         "91.9"
        ],
        [
         "2018-01-02 15:00:01",
         null,
         null,
         "7.2",
         "94.3"
        ],
        [
         "2018-01-02 16:00:01",
         null,
         null,
         "6.5",
         "100.3"
        ],
        [
         "2018-01-02 17:00:01",
         null,
         null,
         "6.3",
         "103.5"
        ],
        [
         "2018-01-02 18:00:01",
         null,
         null,
         "6.6",
         "104.7"
        ],
        [
         "2018-01-02 19:00:01",
         null,
         null,
         "7.8",
         "103.2"
        ],
        [
         "2018-01-02 20:00:01",
         null,
         null,
         "8.7",
         "102.0"
        ],
        [
         "2018-01-02 21:00:01",
         null,
         null,
         "9.3",
         "100.7"
        ],
        [
         "2018-01-02 22:00:01",
         null,
         null,
         "10.0",
         "103.2"
        ],
        [
         "2018-01-02 23:00:01",
         null,
         null,
         "11.2",
         "97.6"
        ],
        [
         "2018-01-03 00:00:01",
         null,
         null,
         "11.9",
         "96.0"
        ],
        [
         "2018-01-03 01:00:01",
         null,
         null,
         "12.2",
         "90.7"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 17519
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_temp</th>\n",
       "      <th>predicted_hr</th>\n",
       "      <th>N2OTemp</th>\n",
       "      <th>S2OHR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Heure</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7</td>\n",
       "      <td>82.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>92.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.8</td>\n",
       "      <td>79.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>87.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 19:38:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>91.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 20:38:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8</td>\n",
       "      <td>95.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:38:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>94.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 22:38:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>95.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:38:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>92.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17519 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     predicted_temp  predicted_hr  N2OTemp  S2OHR\n",
       "Date Heure                                                       \n",
       "2018-01-01 00:00:01             NaN           NaN      9.7   82.8\n",
       "2018-01-01 01:00:01             NaN           NaN      9.0   92.2\n",
       "2018-01-01 02:00:01             NaN           NaN      8.9   80.8\n",
       "2018-01-01 03:00:01             NaN           NaN      8.8   79.4\n",
       "2018-01-01 04:00:01             NaN           NaN      8.0   87.6\n",
       "...                             ...           ...      ...    ...\n",
       "2019-12-31 19:38:01             NaN           NaN      2.5   91.9\n",
       "2019-12-31 20:38:01             NaN           NaN      1.8   95.3\n",
       "2019-12-31 21:38:01             NaN           NaN      1.3   94.4\n",
       "2019-12-31 22:38:01             NaN           NaN      1.2   95.3\n",
       "2019-12-31 23:38:01             NaN           NaN      1.3   92.3\n",
       "\n",
       "[17519 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcp_2_6_data_bias_correction_Temp_HR_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58682735",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basilique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc038618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
